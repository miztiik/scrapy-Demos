[{"Answers": {"usr-1": ["Instance ID: i-343feea7 Alright, so I got my site up and running on an EC2 and I was able to view it with the public DNS. I launched to my domain using http://techgenix.com/namecheap-aws-ec2-linux/. I created an elastic IP for the instance, i created four NS records and two A-name record (www, non-www) using route53. I passed these NS records to my domain provider. The domain appears to have propegated - when I go to the URL, I get sent to Amazon, but it seems to resolve to a very old (two restarts ago) public DNS instead of the new one with the elastic IP. I tried accessing the EIP directly, pinging the EIP, accessing the Public DNS directly, pinging the Public DNS, I tried stopping and starting the instance and repeating all previous steps, and I checked that port 80 is open in the security group, but the domain still redirects me to an old public DNS. I can also ssh in using the URL. Chrome gives me the error \"ERR_CONNECTION_TIMED_OUT\" in the browser. Any ideas? Edited by: RachFee on Mar 31, 2017 5:18 AM"], "usr-2": ["Hello, At the moment, I am able to resolve your domain name correctly and I am able to access your site through my browser. I have also checked your resource record sets on Route53 and all the name servers have been set correctly. Can you please clear out your cache from your browse and try again? Regards Ash"]}, "Question": "Instance ID: i-343feea7 Alright, so I got my site up and running on an EC2 and I was able to view it with the public DNS. I launched to my domain using http://techgenix.com/namecheap-aws-ec2-linux/ . I created an elastic IP for the instance, i created four NS records and two A-name record (www, non-www) using route53. I passed these NS records to my domain provider. The domain appears to have propegated - when I go to the URL, I get sent to Amazon, but it seems to resolve to a very old (two restarts ago) public DNS instead of the new one with the elastic IP. I tried accessing the EIP directly, pinging the EIP, accessing the Public DNS directly, pinging the Public DNS, I tried stopping and starting the instance and repeating all previous steps, and I checked that port 80 is open in the security group, but the domain still redirects me to an old public DNS. I can also ssh in using the URL. Chrome gives me the error 'ERR_CONNECTION_TIMED_OUT' in the browser. Any ideas? Edited by: RachFee on Mar 31, 2017 5:18 AM", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252686&tstart=0"},
{"Answers": {"usr-1": ["Hi, I just got an email alert that we're being charged for the full 720h for almost all our instances when its just April 2! Majority of our instances are on 'reserved'.. this doesnt make sense. Acc # is 198975978718. please advise."], "usr-2": ["It affected all our reserved instances.. looks like a billing bug.. unless this is the way reserved instances work? ie charge the full 30 days ahead and on the first day of the month and is \"consumable\" for the month? Edited by: yujb on Apr 2, 2017 5:35 AM"], "usr-3": ["from support: \"Reserved Instances that are Heavy Utilization, All Upfront, Partial Upfront or No Upfront will show the entire month's total of hours and charges in the Billing Console starting at the beginning of the month. However, these RI line items will not increase during the month. You will see a separate line item on your bill which will count the actual hours used for the matching instance type, but at a zero-dollar rate.\""]}, "Question": "Hi, I just got an email alert that we're being charged for the full 720h for almost all our instances when its just April 2! Majority of our instances are on 'reserved'.. this doesnt make sense. Acc # is 198975978718. please advise.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252832&tstart=0"},
{"Answers": {"usr-1": ["I have an elastic beanstalk web server environment sitting behind a load balancer and in order to do testing before production release I was using Apache Benchmark to benchmark the environment, but for some reason all traffic seems to be directed onto one instance. The environment is scaling properly, adding instances according to load, but no matter how many instances are added, the first instance absorbs all ~500 requests per second, causing it to overload. Edited by: geekman2 on Mar 21, 2017 11:17 AM"], "usr-2": ["It turns out the cause was cross zone load balancing not being enabled, for some reason new instances were not being spawned in the same availability zone and therefore were not bearing load accordingly."]}, "Question": "I have an elastic beanstalk web server environment sitting behind a load balancer and in order to do testing before production release I was using Apache Benchmark to benchmark the environment, but for some reason all traffic seems to be directed onto one instance. The environment is scaling properly, adding instances according to load, but no matter how many instances are added, the first instance absorbs all ~500 requests per second, causing it to overload. Edited by: geekman2 on Mar 21, 2017 11:17 AM", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251923&tstart=0"},
{"Answers": {"usr-1": ["Hi. I plan to manage my ssl certificates through awscli and I set up aws_access_key_id, aws_secret_access_key, and region = eu-west-1c . this command or any others don't work: aws ec2 describe-instances ('Connection aborted.', gaierror(-2, 'Name or service not known')) and I got following packets: myIP.64954 > 172.31.0.2.53: 19694+ A? ec2.eu-west-1c.amazonaws.com.eu-west-1.compute.internal. (73) 10:15:43.705182 IP myIP.64954 > 172.31.0.2.53: 34451+ AAAA? ec2.eu-west-1c.amazonaws.com.eu-west-1.compute.internal. (73) 10:15:43.705953 IP 172.31.0.2.53 > myIP.64954: 19694 NXDomain 0/0/0 (73) my dns server is: root@ip-myIP:~# cat /etc/resolv.conf domain eu-west-1.compute.internal search eu-west-1.compute.internal nameserver 172.31.0.2 this server serer seams not able to resolv ec2.eu-west-1c.amazonaws.com.eu-west-1.compute.internal. is there something I missed?"], "usr-2": ["solved. my /etc/resovl.conf had dns completion and added internal dns suffix to all my dns requests. I removed it and it just works fine."]}, "Question": "Hi. I plan to manage my ssl certificates through awscli and I set up aws_access_key_id, aws_secret_access_key, and region = eu-west-1c . this command or any others don't work: aws ec2 describe-instances ('Connection aborted.', gaierror(-2, 'Name or service not known')) and I got following packets: myIP.64954 > 172.31.0.2.53: 19694+ A? ec2.eu-west-1c.amazonaws.com.eu-west-1.compute.internal. (73) 10:15:43.705182 IP myIP.64954 > 172.31.0.2.53: 34451+ AAAA? ec2.eu-west-1c.amazonaws.com.eu-west-1.compute.internal. (73) 10:15:43.705953 IP 172.31.0.2.53 > myIP.64954: 19694 NXDomain 0/0/0 (73) my dns server is: root@ip-myIP:~# cat /etc/resolv.conf domain eu-west-1.compute.internal search eu-west-1.compute.internal nameserver 172.31.0.2 this server serer seams not able to resolv ec2.eu-west-1c.amazonaws.com.eu-west-1.compute.internal. is there something I missed?", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251968&tstart=0"},
{"Answers": {"usr-1": ["Hi, For the past 2 days I have had multiple cases where 2 of my EC2 instances running Ubuntu are not able to connect to RDS databases. 1 is MariaDB and the other is Postgres. When this happens it gives an error \"could not translate host name *******.us-east-1.rds.amazonaws.com to address\". Rebooting the the EC2 instance seems to solve the issue for several hours, but it is now happening multiple times per day. Any ideas how to resolve the issue for good? Thanks! Ron"], "usr-2": ["Looks to be related to an Ubuntu update. https://forums.aws.amazon.com/thread.jspa?threadID=251868&tstart=0 They released an update already. Trying now to see if it resolves the issue."], "usr-3": ["Ubuntu provided a fix in an update. After updating the issue has not happened again."]}, "Question": "Hi, For the past 2 days I have had multiple cases where 2 of my EC2 instances running Ubuntu are not able to connect to RDS databases. 1 is MariaDB and the other is Postgres. When this happens it gives an error 'could not translate host name -------.us-east-1.rds.amazonaws.com to address'. Rebooting the the EC2 instance seems to solve the issue for several hours, but it is now happening multiple times per day. Any ideas how to resolve the issue for good? Thanks! Ron", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252051&tstart=0"},
{"Answers": {"usr-1": ["Hi there, I lost a password to an ec2 instance and am now trying to reset the password using this guide http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2-windows-passwords.html#ResettingAdminPassword. I am stuck on step 8 because the console is not allowing me to attach a 2nd volume to an instance. Anyone have any ideas?"]}, "Question": "Hi there, I lost a password to an ec2 instance and am now trying to reset the password using this guide http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2-windows-passwords.html#ResettingAdminPassword . I am stuck on step 8 because the console is not allowing me to attach a 2nd volume to an instance. Anyone have any ideas?", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252063&tstart=0"},
{"Answers": {"usr-1": ["Trying to stop and now force-stop an unresponsive instance, id is i-f0e95db0, seems to be stuck in stopping state. Could someone from AWS stop it for me?"], "usr-2": ["Instance has now been stopped, thanks!"]}, "Question": "Trying to stop and now force-stop an unresponsive instance, id is i-f0e95db0, seems to be stuck in stopping state. Could someone from AWS stop it for me?", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252040&tstart=0"},
{"Answers": {"usr-1": ["Our Ec2 instance i-cb43cd06 got rebooted automatically at Mar 23 21:50:IST. Not sure what made this to happen. We didn't issue the reboot. Can somebody explain why this happened? thanks Sateesh"], "usr-2": ["Hello Sateesh, On Thursday, March 9, 2017 8:13 AM (PST), the root email address associated with this account received an EC2 Maintenance notification for this instance. The email begins with \"One or more of your Amazon EC2 instances is scheduled for maintenance on 2017-03-23 for 2 hours starting at 16:00 UTC.\" For maintenance events concerning the underlying host associated with the instance, you can always perform a stop/start to migrate the instance to a different underlying host. Alternatively, you can create an AMI of the instance and launch a new instance from the AMI. Replacement instances will not be affected by this scheduled maintenance. Regards, Tim"]}, "Question": "Our Ec2 instance i-cb43cd06 got rebooted automatically at Mar 23 21:50:IST. Not sure what made this to happen. We didn't issue the reboot. Can somebody explain why this happened? thanks Sateesh", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252105&tstart=0"},
{"Answers": {"usr-1": ["The new i3 instances look great and we're looking to scale up with them. Currently our account is locked to 2 tables and it would be great to scale up much higher. Right now we're getting slammed and it would be great to have the limit raised to at least 24 servers. Thanks"], "usr-2": ["Hello, Thanks for your post. Please, fill in the limit increase form as explained in the article below: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-resource-limits.html Regards, Artem"]}, "Question": "The new i3 instances look great and we're looking to scale up with them. Currently our account is locked to 2 tables and it would be great to scale up much higher. Right now we're getting slammed and it would be great to have the limit raised to at least 24 servers. Thanks", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252133&tstart=0"},
{"Answers": {"usr-1": ["Hi, I need to do some cleanup of some unused VPCs and so on. But I am stuck trying to delete the following NICs: eni-d3c1989e eni-0b450046 I always get some permission errors but I don't know why and what I can do. Could anyone point me to the right direction in order to remove them? Thanks"], "usr-2": ["Hello georges-jentgen, Can you please let me know what is the error message that you see while trying to delete those 2 ENIs? I would also appreciate the region and VPC information. Regards Ash"], "usr-3": ["Here are more details about the NICs and the VPCs: When I try detaching the NICs first, I get this error: Error deleting network interface - eni-d3c1989e: You are not allowed to manage 'ela-attach' attachments. The VPCs I try to remove: vpc-1510a671 vpc-3414bf50 All the resources live in eu-west-1. When I try to delete the VPC directly, I get the following error, why I went to EC2 to try to delete the NICs: Network interface 'eni-0b450046' is currently in use. (Service: AmazonEC2; Status Code: 400; Error Code: InvalidParameterValue; Request ID: b0187e9d-854c-4c6e-b8f4-16896a2c59af) Hope this helps. Thx"], "usr-4": ["Hi, The ENIs you are trying to delete are associated with the EFS mount targets. You will have to delete the mount targets form the EFS console to remove the ENIs. Please remember that you need to delete all the resources in a VPC before you can delete it. Regards, Jayakrishnan L."], "usr-5": ["Thanks. I was not aware that the EFS were still there and somehow connected. My bad. It solved my issue and I successfully removed the VPCs. Thanks"]}, "Question": "Hi, I need to do some cleanup of some unused VPCs and so on. But I am stuck trying to delete the following NICs: eni-d3c1989e eni-0b450046 I always get some permission errors but I don't know why and what I can do. Could anyone point me to the right direction in order to remove them? Thanks", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252199&tstart=0"},
{"Answers": {"usr-1": ["Hi, I have a single ec2 instance which has disappeared overnight. My dashboard shows no instances, running or otherwise. My paid (basic) account is in good standing and I've had no communication from Amazon. Does this... just happen sometimes? Is my data lost? -Rob"]}, "Question": "Hi, I have a single ec2 instance which has disappeared overnight. My dashboard shows no instances, running or otherwise. My paid (basic) account is in good standing and I've had no communication from Amazon. Does this... just happen sometimes? Is my data lost? -Rob", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250875&tstart=25"},
{"Answers": {"usr-1": ["I've tried restarting the instance but it doesn't seem to restart. I've looked at a screen capture and it shows waiting to login? Any help appreciated i-6461244e"], "usr-2": ["Never mind. The REBOOT instance took a very long time to execute before it actually rebooted. All is good I'm in now."]}, "Question": "I've tried restarting the instance but it doesn't seem to restart. I've looked at a screen capture and it shows waiting to login? Any help appreciated i-6461244e", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250828&tstart=25"},
{"Answers": {"usr-1": ["We have a VPC running with a VPN back to our company's servers. I have an instance, i-073c256402b3393a8, running the stock Amazon Linux AMI with docker installed and running (only bound to a non-root port). I am unable to ping or ssh into the machine from our side of the VPN, however I can ssh into an identical AMI in the same availability zone, then ssh again into this instance. Some information: The security group allows 22 and ICMP to/from 0.0.0.0/0. /etc/hosts.allow and /etc/hosts.deny are empty. sshd config is clean Rebooting the instance does not help. In fact I believe I noticed that the machine is pingable while it is booting. The instance was launched from an image of from the public cloud, moved to private. The instance type has changed from t2.micro to m4.large. iptables looks OK to me: Chain INPUT (policy ACCEPT) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination DOCKER-ISOLATION all -- 0.0.0.0/0 0.0.0.0/0 DOCKER all -- 0.0.0.0/0 0.0.0.0/0 ACCEPT all -- 0.0.0.0/0 0.0.0.0/0 ctstate RELATED,ESTABLISHED ACCEPT all -- 0.0.0.0/0 0.0.0.0/0 ACCEPT all -- 0.0.0.0/0 0.0.0.0/0 Chain OUTPUT (policy ACCEPT) target prot opt source destination Chain DOCKER (1 references) target prot opt source destination ACCEPT tcp -- 0.0.0.0/0 <an IP here> tcp dpt:<user port> Chain DOCKER-ISOLATION (1 references) target prot opt source destination RETURN all -- 0.0.0.0/0 0.0.0.0/0 Any help would be appreciated. This scenario is reproducible. UPDATE: Turns out this was due to the subnet that docker uses for its default docker0 interface colliding with the subnet we have routed our VPN with. (172.17.0.0/16) Changing /etc/docker/daemon.config to include { \"bip\": \"10.0.0.1/24\" } resolved the issue. Edited by: LucasAzzola on Apr 4, 2017 12:43 AM"]}, "Question": "We have a VPC running with a VPN back to our company's servers. I have an instance, i-073c256402b3393a8, running the stock Amazon Linux AMI with docker installed and running (only bound to a non-root port). I am unable to ping or ssh into the machine from our side of the VPN, however I can ssh into an identical AMI in the same availability zone, then ssh again into this instance. Some information: The security group allows 22 and ICMP to/from 0.0.0.0/0. /etc/hosts.allow and /etc/hosts.deny are empty. sshd config is clean Rebooting the instance does not help. In fact I believe I noticed that the machine is pingable while it is booting. The instance was launched from an image of from the public cloud, moved to private. The instance type has changed from t2.micro to m4.large. iptables looks OK to me: Chain INPUT (policy ACCEPT) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination DOCKER-ISOLATION all -- 0.0.0.0/0 0.0.0.0/0 DOCKER all -- 0.0.0.0/0 0.0.0.0/0 ACCEPT all -- 0.0.0.0/0 0.0.0.0/0 ctstate RELATED,ESTABLISHED ACCEPT all -- 0.0.0.0/0 0.0.0.0/0 ACCEPT all -- 0.0.0.0/0 0.0.0.0/0 Chain OUTPUT (policy ACCEPT) target prot opt source destination Chain DOCKER (1 references) target prot opt source destination ACCEPT tcp -- 0.0.0.0/0 <an IP here> tcp dpt:<user port> Chain DOCKER-ISOLATION (1 references) target prot opt source destination RETURN all -- 0.0.0.0/0 0.0.0.0/0 Any help would be appreciated. This scenario is reproducible. UPDATE: Turns out this was due to the subnet that docker uses for its default docker0 interface colliding with the subnet we have routed our VPN with. (172.17.0.0/16) Changing /etc/docker/daemon.config to include { 'bip': '10.0.0.1/24' } resolved the issue. Edited by: LucasAzzola on Apr 4, 2017 12:43 AM", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252890&tstart=0"},
{"Answers": {"usr-1": ["Hi For some reason I can't connect to our instance i-42a5d6a8. I tried the following: 1. Stopped and started the instance through the AWS Console. 2. Created an image of the instance and launched it as a new instance. Can't connect to the new instance either. Both the System and Instance Health Checks for the instance shows that it passed. Please help. Andr\u00e9"], "usr-2": ["The issue was related to a security group that only allowed SSH traffic from certain IP Address. After modifying the security group, I was able to connect to the server again."]}, "Question": "Hi For some reason I can't connect to our instance i-42a5d6a8. I tried the following: 1. Stopped and started the instance through the AWS Console. 2. Created an image of the instance and launched it as a new instance. Can't connect to the new instance either. Both the System and Instance Health Checks for the instance shows that it passed. Please help. Andr\u00e9", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251780&tstart=25"},
{"Answers": {"usr-1": ["I have started a Amazon EC2 instance (Redhat 7.3) and opened ports 22, 80, 8080 in my Security Group. I have created an elastic IP address and connected it to the the instance. I also have opened the same ports (22,80,8080) from the firewall on my redhat instance. root@ip-172-31-4-148 ec2-user# iptables-save Generated by iptables-save v1.4.21 on Mon Apr 3 08:02:25 2017 *filter :INPUT ACCEPT https://forums.aws.amazon.com/ :FORWARD ACCEPT https://forums.aws.amazon.com/ :OUTPUT ACCEPT https://forums.aws.amazon.com/ -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT -A INPUT -p icmp -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT -A INPUT -p tcp -m tcp --dport 80 -j ACCEPT -A INPUT -p tcp -m tcp --dport 8080 -j ACCEPT -A INPUT -p tcp -m tcp --dport 9200 -j ACCEPT -A INPUT -p tcp -m tcp --dport 9990 -j ACCEPT -A INPUT -j REJECT --reject-with icmp-host-prohibited -A FORWARD -j REJECT --reject-with icmp-host-prohibited COMMIT root@ip-172-31-4-148 ec2-user# netstat -plnt Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:8080 0.0.0.0:* LISTEN 3099/java tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1917/sshd tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1141/master tcp 0 0 127.0.0.1:9990 0.0.0.0:* LISTEN 3099/java tcp6 0 0 :::22 :::* LISTEN 1917/sshd tcp6 0 0 ::1:25 :::* LISTEN 1141/master However, I still cannot connect to port 8080 from my browsers. I've tried type it using public IP (http://x.x.x.x:8080) or by public DNS, it always says connection timeout. Is there any configuration that I've missed? Any helps really appreciated. Thanks"], "usr-2": ["1. Did you start up Apache? 2. Did you configure Apache to answer to port 8080? 3. Do you have another security application running that might be blocking port 8080? 4. Did you allow it in TCP Wrappers (/etc/hosts.deny or hosts.allow)? 5. Is it in a VPC? Is port 8080 allowed into the VPC? Hope this helps guide you to an answer..."], "usr-3": ["Hi Victor, I just found that I forgot to configured the public IP address in my Jboss. After fixing it, I can finally open web application (port 8080) from outside. Thanks for the help!!!"]}, "Question": "I have started a Amazon EC2 instance (Redhat 7.3) and opened ports 22, 80, 8080 in my Security Group. I have created an elastic IP address and connected it to the the instance. I also have opened the same ports (22,80,8080) from the firewall on my redhat instance. root@ip-172-31-4-148 ec2-user # iptables-save Generated by iptables-save v1.4.21 on Mon Apr 3 08:02:25 2017 -filter :INPUT ACCEPT https://forums.aws.amazon.com/ :FORWARD ACCEPT https://forums.aws.amazon.com/ :OUTPUT ACCEPT https://forums.aws.amazon.com/ -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT -A INPUT -p icmp -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT -A INPUT -p tcp -m tcp --dport 80 -j ACCEPT -A INPUT -p tcp -m tcp --dport 8080 -j ACCEPT -A INPUT -p tcp -m tcp --dport 9200 -j ACCEPT -A INPUT -p tcp -m tcp --dport 9990 -j ACCEPT -A INPUT -j REJECT --reject-with icmp-host-prohibited -A FORWARD -j REJECT --reject-with icmp-host-prohibited COMMIT root@ip-172-31-4-148 ec2-user # netstat -plnt Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:8080 0.0.0.0:- LISTEN 3099/java tcp 0 0 0.0.0.0:22 0.0.0.0:- LISTEN 1917/sshd tcp 0 0 127.0.0.1:25 0.0.0.0:- LISTEN 1141/master tcp 0 0 127.0.0.1:9990 0.0.0.0:- LISTEN 3099/java tcp6 0 0 :::22 :::- LISTEN 1917/sshd tcp6 0 0 ::1:25 :::- LISTEN 1141/master However, I still cannot connect to port 8080 from my browsers. I've tried type it using public IP ( http://x.x.x.x:8080 ) or by public DNS, it always says connection timeout. Is there any configuration that I've missed? Any helps really appreciated. Thanks", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252875&tstart=0"},
{"Answers": {"usr-1": ["I have 2 ALBs that are do not appear to be listening on the port defined. These were working up until earlier today but no longer are accessible. The instances are healthy/active and the backends are receiving healthcheck 200s from the load balancers. These were provisioned last week and were working, but arent anything longer. Things tried: 1. Re-provisioned the ALBs 2. Changed the listeners 3. Changed security groups (this is in use by other working load balancers) Please advise."], "usr-2": ["Check the subnets that are used for the ALB. Maybe a route table issue."]}, "Question": "I have 2 ALBs that are do not appear to be listening on the port defined. These were working up until earlier today but no longer are accessible. The instances are healthy/active and the backends are receiving healthcheck 200s from the load balancers. These were provisioned last week and were working, but arent anything longer. Things tried: 1. Re-provisioned the ALBs 2. Changed the listeners 3. Changed security groups (this is in use by other working load balancers) Please advise.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250942&tstart=25"},
{"Answers": {"usr-1": ["volume id : vol-0e410ebdc694997561 instance id : i-028bae53d036132a3 I see very very low I/O performance from my main server instance. I've found that cloudwatch is reporting quite high read bandwidth than usual. (usual 50, now more than 2500) Also Average Queue length is higher than usual (usual 5, now 60) It happened about 10 hours ago. Not actual modification from my side, but suddenly server acted like this. The problem is that I don't find any doubtful process or works from various I/O monitoring tools. I tried iotop, fatrace, and several things but couldn't find any. I created swap but swap is almost not used. Memory has enough space too. I first thought that it was because of not fully warmed EBS because this instance started about a week ago. But I don't think that is causing problem looking at abnormal cloudwatch read bandwidth. It's quite nonsense that I can't find which process is making problem while cloudwatch is reporting abnormal behaviours. It's like hidden or transparent, not calculated from my side. There's no apparent read bandwidth consuming things. I attached cloudwatch screenshot. read bandwidth, read iops. r/s is not even close to cloudwatch numbers when I type iostat -dx to see read iops. (5~50 currently) I'm now thinking that EBS volume or some infra under AWS is broken. Please advice me. Edited by: childly on Mar 7, 2017 11:18 PM"], "usr-2": ["I also experience very low disk IO speeds recently (well below the baseline). However, in my case it's for newly created instances. Therefore, my guess was that it has something to do with pre-warming. Can you try to run the code as given in http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html ? sudo fio --filename=/dev/xvdf --rw=randread --bs=128k --iodepth=32 --ioengine=libaio --direct=1 --name=volume-initialize (You probably have to change \"xvdf\" to \"xvda\" or similar) When I use this pre-warming routine for a newly created instance, I get very low IOPS for the first run (like 10-30 in my case). But for the second run (or for instances that have been up for a few months), I get bursting IOPS of 700-1000. I am curious how your IO is after running the above command!"], "usr-3": ["I changed to business support plan. (AWS never replied to my questions, so I paid) I thought that it's definitely AWS's infra problem, and I had to contact their staff to fix. Some tech analyzed and said it's because of pre-warming issue. I actually pre-warmed for few hours, but all things were already acting well and I stopped. As it's not mandatory for usual workloads, I didn't want to waste IOPS resources. Also I had assigned 3000 IOPS for that volume, so it will get blocks on the fly quickly. I ran server for more than 5 days without problem from initialization. But suddenly it broke. I/O performance dropped drastically. I now know that AWS is built on totally different architecture from other cloud services. I don't know much about pre-warming/initialization, but it should be done. I'll continually look and monitor if any issue happens. I hope no server fault any more. Thanks for your answer. Edited by: childly on Mar 14, 2017 1:13 AM"], "usr-4": ["I'm having a similar issue. I've seen this issue a handful of times now with different root volumes from different servers. Out of the blue, something begins reading the entire root disk and it's not me or anyone else. I've also observed it happening more than once on the same volume, days apart. What's odd is that the cloudwatch graphs show high bandwidth and IOPS during this event, but my munin graphs do not. Looking at the cloudwatch graphs, I was able to calculate the total bandwidth consumed was exactly equal to the size of the disk. When the event occurs, it scans the entire disk at full speed at 4KB/op."]}, "Question": "volume id : vol-0e410ebdc694997561 instance id : i-028bae53d036132a3 I see very very low I/O performance from my main server instance. I've found that cloudwatch is reporting quite high read bandwidth than usual. (usual 50, now more than 2500) Also Average Queue length is higher than usual (usual 5, now 60) It happened about 10 hours ago. Not actual modification from my side, but suddenly server acted like this. The problem is that I don't find any doubtful process or works from various I/O monitoring tools. I tried iotop, fatrace, and several things but couldn't find any. I created swap but swap is almost not used. Memory has enough space too. I first thought that it was because of not fully warmed EBS because this instance started about a week ago. But I don't think that is causing problem looking at abnormal cloudwatch read bandwidth. It's quite nonsense that I can't find which process is making problem while cloudwatch is reporting abnormal behaviours. It's like hidden or transparent, not calculated from my side. There's no apparent read bandwidth consuming things. I attached cloudwatch screenshot. read bandwidth, read iops. r/s is not even close to cloudwatch numbers when I type iostat -dx to see read iops. (5~50 currently) I'm now thinking that EBS volume or some infra under AWS is broken. Please advice me. Edited by: childly on Mar 7, 2017 11:18 PM", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250907&tstart=25"},
{"Answers": {"usr-1": ["I'm trying to set up SSL/TLS for a test server, but I'm stuck. The EC2 instance is set-up and the web site all works. I've created an elastic IP, connected it to the instance, and pointed my DNS/domain at it. All works fine (http). I've used ACM to create a certificate for the domain. It's been approved and issued. Now I'm stuck trying to figure out how to install the certificate. I assumed I'd just point the certificate to the elastic IP or to the instance. But I can't find a way to do that. Is there existing documentation on that process? Thanks Bill Edited by: billmccollam on Mar 3, 2017 5:07 PM"], "usr-2": ["Retracting the question. I guess the ACM cert can only be used with a load balance or cloudfront front-end - not for a bare ec2 instance or elastic IP. I simply ended up creating the certificate and self-signing it and installing it on the ec2 instance. All worked fine. Carry on."]}, "Question": "I'm trying to set up SSL/TLS for a test server, but I'm stuck. The EC2 instance is set-up and the web site all works. I've created an elastic IP, connected it to the instance, and pointed my DNS/domain at it. All works fine (http). I've used ACM to create a certificate for the domain. It's been approved and issued. Now I'm stuck trying to figure out how to install the certificate. I assumed I'd just point the certificate to the elastic IP or to the instance. But I can't find a way to do that. Is there existing documentation on that process? Thanks Bill Edited by: billmccollam on Mar 3, 2017 5:07 PM", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250599&tstart=50"},
{"Answers": {"usr-1": ["Hi, I have an issue with spot request console we make a request everyday that created around 9AM and is expiring around 9PM after which i parse the describe spot instance requests to extract the instance ID and terminate it. A week ago i noticed that that expired requests are not disappearing from the console causing the script that terminates the instances to fail as the instances are not being found. Can you help? Alex"], "usr-2": ["Althou the requests disappeared temporarily but now i see them again"], "usr-3": ["Hello, Thank you for getting in touch with us. We're investigating the issue, and we'll get back in touch with you with our findings."], "usr-4": ["Hi Chris, Do you guys have any updates or do you need anymore info regarding this issue. I figured out that the request is blocked since the 28th of February."], "usr-5": ["Hi, I got an update from the service team that the issue has been solved. Please confirm if you are still experiencing the issue. Thanks!!!"], "usr-6": ["Everything is ok now. Thanks!"]}, "Question": "Hi, I have an issue with spot request console we make a request everyday that created around 9AM and is expiring around 9PM after which i parse the describe spot instance requests to extract the instance ID and terminate it. A week ago i noticed that that expired requests are not disappearing from the console causing the script that terminates the instances to fail as the instances are not being found. Can you help? Alex", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250951&tstart=25"},
{"Answers": {"usr-1": ["I started looking at AWS and decided to begin with the 10 minute tutorials. I've already hit a problem though. Having created my Linux Instance(https://aws.amazon.com/getting-started/tutorials/launch-a-virtual-machine/) I then created my elastic ip(https://aws.amazon.com/getting-started/tutorials/get-a-domain/). This is where I hit an issue. I reached \"g. Verify that your new Elastic IP address is working by typing it into your web browser.\". My browser timed out at this step. Am I missing something? How do I get around this issue? Thanks Paul"], "usr-2": ["Hello, Taking a look at the only instance you have launched I see it's ready for web traffic as all routing and security elements of AWS are properly configured. However the OS is actively refusing connections to TCP port 80, which indicates that there is no web software installed or it's misconfigured or not running. The first tutorial covers how to launch a linux EC2 instance, and doesn't cover installing or configuring any additional web software. The second tutorial linked covers how to register a domain name for a EC2 instance already configured with web software. Without any web software installed you won't be able to browse to the EIP in your browser. You can go through installing web software yourself, or if you wanted a tutorial on how to configure this you may want to start with the following tutorial, which is referenced by your second tutorial under step \"e.\": https://aws.amazon.com/getting-started/tutorials/launch-a-wordpress-website/ Regards, Nick"], "usr-3": ["Thanks Nick. Just tried that. Works perfectly. Edited by: runnerpaul on Feb 15, 2017 3:49 AM"]}, "Question": "I started looking at AWS and decided to begin with the 10 minute tutorials. I've already hit a problem though. Having created my Linux Instance( https://aws.amazon.com/getting-started/tutorials/launch-a-virtual-machine/ ) I then created my elastic ip( https://aws.amazon.com/getting-started/tutorials/get-a-domain/ ). This is where I hit an issue. I reached 'g. Verify that your new Elastic IP address is working by typing it into your web browser.'. My browser timed out at this step. Am I missing something? How do I get around this issue? Thanks Paul", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249224&tstart=75"},
{"Answers": {"usr-1": ["Is there something you have to do to get instances launched through auto scaling acquire an IPv6 address? I have IPv6 set up on my VPC so any instances manually launched into it get an address, but instances launched via auto scaling don't."], "usr-2": ["Hi, Instances launched in IPv6 enabled VPC should have an IPv6 address whether launched manually or through Autoscale. Please note the following: If your instances are being launched from an AMI that is not configured to use DHCPv6, you must manually configure your instance to recognize an IPv6 address assigned to the instance. if your instance was launched from an AMI that uses PV virtualization, the only instance type that supports both PV virtualization and IPv6 is C3. This instance type may not be suitable for your needs. In this case, you may have to reinstall your software on a base HVM AMI, and launch a new instance. Please check your AMI and verify if it supports IPv6: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#instance-networking-storage Regards, Souza S"], "usr-3": ["Thanks, that's fixed it. I didn't realise the Amazon Linux AMI had been updated."]}, "Question": "Is there something you have to do to get instances launched through auto scaling acquire an IPv6 address? I have IPv6 set up on my VPC so any instances manually launched into it get an address, but instances launched via auto scaling don't.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249244&tstart=75"},
{"Answers": {"usr-1": ["Hi, Here is a screenshot: https://imagebin.ca/v/3Hh2DPJtOrkK I was trying to instantiate an AMI from the MarketPlace but I was unable to proceed. I tried Kali and Debian 8. I tried from Chrome and Firefox on Windows and Firefox on Linux. Same result. Anybody know what's going on?"], "usr-2": ["up"], "usr-3": ["Receiving the same error as the topic starter. Also tried multiple browsers. Edited by: danny on Apr 3, 2017 12:55 AM Update: issue has been resolved. Edited by: danny on Apr 3, 2017 3:57 AM"], "usr-4": ["I still have the issue. Did you do anything special to resolve the issue?"], "usr-5": ["I have been able to launch my instance now. Didn't changed anything. No idea why this issue happened or how it was resolved."], "usr-6": ["No solution was provided. Issue was solved automagically"]}, "Question": "Hi, Here is a screenshot: https://imagebin.ca/v/3Hh2DPJtOrkK I was trying to instantiate an AMI from the MarketPlace but I was unable to proceed. I tried Kali and Debian 8. I tried from Chrome and Firefox on Windows and Firefox on Linux. Same result. Anybody know what's going on?", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252835&tstart=0"},
{"Answers": {"usr-1": ["We have a scheduled change for instance i-e98dfe8f due to the underlying hardware needing to be replaced. I have twice stopped then started this instance but this has either not forced a migration or cancelled the change notice, or both."], "usr-2": ["Hi, I could confirm that the instance - i-e98dfe8f does not have any scheduled maintenance events. From the Events page in AWS EC2 console, you might see the scheduled event with 'https://forums.aws.amazon.com/' status. Regards, Jayakrishnan L"], "usr-3": ["Hello. Although I appreciate your looking into this the \"EC2 persistent instance retirement scheduled\" notice is still showing, after 3 stops then starts. I have double checked that the instance in question is \"i-e98dfe8f\". I have double checked that the tagged name matches the server I have stopped then restarted. If the scheduled change has been cancelled could you see if you could have the notice on our end removed? Thank-you very much for your attention to this."], "usr-4": ["The notice is gone and the server was not restarted, so I think my restart dealt with the issue without clearing the notice on our account dashboard."]}, "Question": "We have a scheduled change for instance i-e98dfe8f due to the underlying hardware needing to be replaced. I have twice stopped then started this instance but this has either not forced a migration or cancelled the change notice, or both.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249274&tstart=75"},
{"Answers": {"usr-1": ["So, I have received AWS Credits for Student program. I have Amazon Elastic Cloud Compute (EC2) as eligible service in Applicable Products where credit can be applied. I want to know does that also include Amazon Elastic Block Store (EBS) that are attached to the instances? Because I cannot find Amazon EBS in eligible services. Thanks, DRiFT Edited by: DRiFT on Feb 15, 2017 6:13 AM"]}, "Question": "So, I have received AWS Credits for Student program. I have Amazon Elastic Cloud Compute (EC2) as eligible service in Applicable Products where credit can be applied. I want to know does that also include Amazon Elastic Block Store (EBS) that are attached to the instances? Because I cannot find Amazon EBS in eligible services. Thanks, DRiFT Edited by: DRiFT on Feb 15, 2017 6:13 AM", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249313&tstart=75"},
{"Answers": {"usr-1": ["I have a Windows EC2 Instance with Detailed Monitoring on. Sometimes a service on the server will enter a state where it \"pegs\" the CPU, taking up 100% of the CPU (see screenshot). However at the same time the CloudWatchCPU does not reflect this; it stays at a constant around 20%, even though the period is set to one minute (see screenshot). Why the deviation? Why doesn't CloudWatch reflect that the CPU according to Task Manager is 100%? Thanks, Mark. Edited by: mjschenkel on Feb 15, 2017 11:06 AM Added reference to screenshot."], "usr-2": ["I did further research on the issue and came across this article: https://acloud.guru/forums/aws-certified-solutions-architect-associate/discussion/-KB7tIhPJEg8k3LsCQh8/confused-about-cpu-utilization-vs-cpu-uage This seems to imply that the CPU I am seeing on Windows could be attributed to other servers on the VM using more CPU themselves. Is this correct? It also talks about \"Credits\". Do I need to move to an instance where my CPU/performance will not be affected by other instances on the server? Edited by: mjschenkel on Feb 15, 2017 12:42 PM"], "usr-3": ["I found out after doing more research this is the case with T2 instances."]}, "Question": "I have a Windows EC2 Instance with Detailed Monitoring on. Sometimes a service on the server will enter a state where it 'pegs' the CPU, taking up 100\\% of the CPU (see screenshot). However at the same time the CloudWatchCPU does not reflect this; it stays at a constant around 20\\%, even though the period is set to one minute (see screenshot). Why the deviation? Why doesn't CloudWatch reflect that the CPU according to Task Manager is 100\\%? Thanks, Mark. Edited by: mjschenkel on Feb 15, 2017 11:06 AM Added reference to screenshot.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249365&tstart=75"},
{"Answers": {"usr-1": ["Hello to everyone, I need a clarification on something. I have installed Moodle on an 2 EC2 instances as cluster. Moodle is using PHPMailer. In the settings of Moodle I have set the SMTP host as email-smtp.us-east-1.amazonaws.com Since our Moodle is sending a LOT of emails, we have requested to upgrade SES so that the limit is raised but my question is: do I need to request a raise limit of sending emails of my EC2 instances as well? Thank you Kind regards Christos"]}, "Question": "Hello to everyone, I need a clarification on something. I have installed Moodle on an 2 EC2 instances as cluster. Moodle is using PHPMailer. In the settings of Moodle I have set the SMTP host as email-smtp.us-east-1.amazonaws.com Since our Moodle is sending a LOT of emails, we have requested to upgrade SES so that the limit is raised but my question is: do I need to request a raise limit of sending emails of my EC2 instances as well? Thank you Kind regards Christos", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249380&tstart=75"},
{"Answers": {"usr-1": ["Hi everyone, just curious maybe somebody else faced with the similar issue before and can share any insights. The problem: IBM Domino Server x64 (v9.0.1 - any FixPacks, including latest FP7 as of today) - periodically reboots (once per day) on the CentOS 6.8 deployed on EC2 VM instance (t2.micro / t2.small). NSD runs and collects the diagnostics data, but we can not find any reasons for such reboots. The same version of Domino in the same configuration works absolutely fine on other VM instances (VMware ESXi 6, Linux KVM) with the same resources (1 vCPU, 2 GB RAM). But it always crashes on AWS EC2 T2 instances. Even more, we have one test instance running months without anybody accessing it - and it also reboots every 2-4 days... Thank you!"], "usr-2": ["I was able to find the reason of such reboots: it turned out that by default Amazon (AMI) Linux images (CentOS 6, CentOS 7, RedHat 7 \u2013 those I have tested) doesn\u2019t have swap enabled! Thus system doesn't have swap space at all, only RAM. AS result long-running memory-high-consuming processes are being killed by Linux Kernel (OOM killer). All what you need to do in order to fix the issue \u2013 is just enable the swap (add swap file or swap partition). This topic has helped me much: http://serverfault.com/questions/268288/most-long-running-commands-instantly-killed-on-amazon-ec2-ubuntu-10-04"]}, "Question": "Hi everyone, just curious maybe somebody else faced with the similar issue before and can share any insights. The problem : IBM Domino Server x64 (v9.0.1 - any FixPacks, including latest FP7 as of today) - periodically reboots (once per day) on the CentOS 6.8 deployed on EC2 VM instance (t2.micro / t2.small). NSD runs and collects the diagnostics data, but we can not find any reasons for such reboots. The same version of Domino in the same configuration works absolutely fine on other VM instances (VMware ESXi 6, Linux KVM) with the same resources (1 vCPU, 2 GB RAM). But it always crashes on AWS EC2 T2 instances. Even more, we have one test instance running months without anybody accessing it - and it also reboots every 2-4 days... Thank you!", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249426&tstart=75"},
{"Answers": {"usr-1": ["Hi All, I have a couple of m1.small instances that are Active Directory controllers for my Windows domain. I'd like to upgrade them to t2.small instances. Is there a way I can just change the instance type, rather than having to go through the whole domain migration thing? Thanks! -Steve"], "usr-2": ["Hi Steve, You can normally change your instance type by stopping the instance, then right-clicking your instance in the list, then go to Instance Settings -> Change Instance Type. But in this case you want to go from m1.small to t2.small, and those instance types have different virtualization types (paravirtual versus hvm), so it will not work. I don't know if there's a good way but to reinstall everything. Hopefully an AWS employee can chime in. More information here: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-resize.html#resize-limitations I hope this helped you. Stefan"], "usr-3": ["Thanks for the reply. However... I just stopped my instance and was able to change the instance type from a m1.small to a t2.small. So I'm good to go!"]}, "Question": "Hi All, I have a couple of m1.small instances that are Active Directory controllers for my Windows domain. I'd like to upgrade them to t2.small instances. Is there a way I can just change the instance type, rather than having to go through the whole domain migration thing? Thanks! -Steve", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249463&tstart=75"},
{"Answers": {"usr-1": ["Ok I've got this working 90% of the way. I just need to get to the finish line. We are using the ELB to strip out the SSL and communicate to the EC2 instance via HTTP as recommended. As you know wordpress is a little finicky with this. But it's at the point that every page that's accessed via https loads properly. I just want to make sure that anybody that hits the site via http gets redirected to HTTPS no matter if they are on the homepage or a sub page. In my htaccess I have RewriteCond %{HTTP:X-Forwarded-Proto} !https RewriteRule .* https://%{HTTP_HOST}%{REQUEST_URI} [R=301,L] And in my wp-config I have: define('WP_HOME','https://www.domain.com'); define('WP_SITEURL','https://www.domain.com'); \u00a0 define('FORCE_SSL_ADMIN', true); \u00a0 if (strpos($_SERVER['HTTP_X_FORWARDED_PROTO'], 'https') !== false) $_SERVER['HTTPS']='on'; This successfully will redirect as follows: http://www.domain.com/ \u2192 https://www.domain.com/ But if somebody manually puts in a page name like /about the redirect doesn't happen. It should redirect to this: http://www.domain.com/about \u2192 https://www.domain.com/about but that is not working."], "usr-2": ["Hi... What does happen?"], "usr-3": ["It just goes to http://www.domain.com/about It does not redirect to the HTTPS"], "usr-4": ["Might be worth giving these a try? Probably not what you wanted but if they get the job done it must be useful? https://en-gb.wordpress.org/plugins/really-simple-ssl/ https://en-gb.wordpress.org/plugins/https-redirection/ Also, have you tried rewriting on the port rather than the protocol? RewriteCond %{SERVER_PORT} 80 RewriteRule ^(.*)$ https://www.domain.com/$1 [R=301,L]"], "usr-5": ["I'll try the plugins next. But no luck on port. I've even gone in and completely stripped down my .htaccess to the bare minimum thinking I may have some conflicts with W3TC. I know that mod_rewrite is on from phpinfo and I know for sure that .htaccess is being read because I'm able to break the site by putting 'Test.' in the first line. # BEGIN WordPress <IfModule mod_rewrite.c> RewriteEngine On RewriteBase /\u00a0 RewriteRule ^index\\.php$ - [L] RewriteCond %{REQUEST_FILENAME} !-f RewriteCond %{REQUEST_FILENAME} !-d RewriteRule . /index.php [L] RewriteCond %{HTTP:X-Forwarded-Proto} !https RewriteRule .* https://%{HTTP_HOST}%{REQUEST_URI} [R=301,L] </IfModule> # END WordPress or this one # BEGIN WordPress <IfModule mod_rewrite.c> RewriteEngine On RewriteBase /\u00a0 RewriteRule ^index\\.php$ - [L] RewriteCond %{REQUEST_FILENAME} !-f RewriteCond %{REQUEST_FILENAME} !-d RewriteRule . /index.php [L] RewriteCond %{SERVER_PORT} 80 RewriteRule ^(.*)$ https://www.domain.com/$1 [R=301,L] </IfModule> \u00a0 # END WordPress but in either one I'm beginning to think the Condition is never met. Edited by: oceanthirsty on Feb 17, 2017 11:41 AM"], "usr-6": ["Here's the solution I found. Not sure why it works this way. But it does. I ended up moving the RewriteCond & RewriteRule from the .htaccess to my .conf file and everything is working now as expected."], "usr-7": ["Interesting... Thanks for the update, worth submitting to memory"]}, "Question": "Ok I've got this working 90\\% of the way. I just need to get to the finish line. We are using the ELB to strip out the SSL and communicate to the EC2 instance via HTTP as recommended. As you know wordpress is a little finicky with this. But it's at the point that every page that's accessed via https loads properly. I just want to make sure that anybody that hits the site via http gets redirected to HTTPS no matter if they are on the homepage or a sub page. In my htaccess I have RewriteCond \\% { HTTP:X-Forwarded-Proto } !https RewriteRule .- https: //\\%{HTTP_HOST}\\%{REQUEST_URI} [R=301,L] And in my wp-config I have: define( 'WP_HOME' , 'https://www.domain.com' ); define( 'WP_SITEURL' , 'https://www.domain.com' ); \u00a0 define( 'FORCE_SSL_ADMIN' , true ); \u00a0 if (strpos($_SERVER[ 'HTTP_X_FORWARDED_PROTO' ], 'https' ) !== false ) $_SERVER[ 'HTTPS' ]= 'on' ; This successfully will redirect as follows: http: //www.domain.com/ \u2192 https://www.domain.com/ But if somebody manually puts in a page name like /about the redirect doesn't happen. It should redirect to this: http: //www.domain.com/about \u2192 https://www.domain.com/about but that is not working.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249345&tstart=75"},
{"Answers": {"usr-1": ["We have a t2.2xlarge AWS EC instance that we use as a Remote Desktop Server. Most or the workload on this instance takes place in weekdays from 08:00 to 18:00. We expected our CPU balance to go down during business hours and to go up during nights and weekends. The t2.2xlarge instance has a baseline CPU of 135%, so since it has 8 vCPUs, the baseline system CPU utilization should be 135/8 = 16.875% However, we are seeing a strange behaviour on nights, CPU balance not always grows in spite of CPU utilization being at the lowest, well below the 16.875% baseline. For example, see in the attachments the monitoring graphs for CPU Utilization, CPU credits and CPU balance for the last 24 hours. As you can see in the attachments, the lowest CPU utilization and CPU credit usage for the instance take place during 23:00 and 6:00, but it spite of that, the CPU balance during that period of time is flat, when we expected it to grow a lot faster than it grows from 18:00 to 23:00. Why does that happen? What should we do to have the instance gain CPU credits during the periods of very low activity?"], "usr-2": ["I ended up finding the answer here: http://stackoverflow.com/questions/32256886/ec2-t2-medium-burstable-credit-savings-calcuation"], "usr-3": ["Hello I'm happy that you found an answer to your question, also you can find more details on our documentation by visiting the below links: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/t2-instances.html#t2-instances-cpu-credits https://aws.amazon.com/blogs/aws/low-cost-burstable-ec2-instances/ Have a nice day, and please don't hesitate to contact us for further assistance."]}, "Question": "We have a t2.2xlarge AWS EC instance that we use as a Remote Desktop Server. Most or the workload on this instance takes place in weekdays from 08:00 to 18:00. We expected our CPU balance to go down during business hours and to go up during nights and weekends. The t2.2xlarge instance has a baseline CPU of 135\\%, so since it has 8 vCPUs, the baseline system CPU utilization should be 135/8 = 16.875\\% However, we are seeing a strange behaviour on nights, CPU balance not always grows in spite of CPU utilization being at the lowest, well below the 16.875\\% baseline. For example, see in the attachments the monitoring graphs for CPU Utilization, CPU credits and CPU balance for the last 24 hours. As you can see in the attachments, the lowest CPU utilization and CPU credit usage for the instance take place during 23:00 and 6:00, but it spite of that, the CPU balance during that period of time is flat, when we expected it to grow a lot faster than it grows from 18:00 to 23:00. Why does that happen? What should we do to have the instance gain CPU credits during the periods of very low activity?", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249532&tstart=75"},
{"Answers": {"usr-1": ["Hi, It looks like my instance (i-0d909b84b71f0c502) was restarted at Feb 16 19:46:20 CST. At that moment we weren't doing any maintenance and according to a log it was a hard reset. Would explain why there was a restart?"], "usr-2": ["Hi, Apologies for the troubles caused, I could see that the underlying hardware has got rebooted because of some connectivity issues. This has caused your instance to reboot as well. However, I could see that the instance and its underlying hardware are healthy now. However, you may do a stop and start so that the instance will move to a new underlying hardware. Apologies again for the troubles. Regards, Jayakrishnan L."], "usr-3": ["Hi, Thank you for the clarification. Do I understand correctly, I should only do start and stop the instance and underlying hardware will be change automatically?"]}, "Question": "Hi, It looks like my instance (i-0d909b84b71f0c502) was restarted at Feb 16 19:46:20 CST. At that moment we weren't doing any maintenance and according to a log it was a hard reset. Would explain why there was a restart?", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249541&tstart=75"},
{"Answers": {"usr-1": ["I am trying to import a raw image. The partition layout of the raw image are as follows: Number Start (sector) End (sector) Size Code Name 1 2048 1050623 512.0 MiB EF00 boot_raid_1 2 1050624 1071103 10.0 MiB EF02 boot_raid_2 3 1071104 22042623 10.0 GiB 8300 root_raid_1 4 22042624 22063103 10.0 MiB 8300 root_raid_2 5 22063104 38840319 8.0 GiB 8300 config_raid 6 38840320 134217694 45.5 GiB 8300 local_raid The import is failing with the following: { \"ImportImageTasks\": [ { \"Status\": \"deleted\", \"SnapshotDetails\": [ { \"UserBucket\": { \"S3Bucket\": \"dateravms\", \"S3Key\": \"DateraOS-sda.raw\" }, \"DiskImageSize\": 68719476736.0, \"Description\": \"Datera raw\", \"Format\": \"RAW\" } ], \"Description\": \"Datera raw\", \"StatusMessage\": \"ClientError: No valid partitions. Not a valid volume.\", \"ImportTaskId\": \"import-ami-fgwkj0j7\" } ] } Any suggestions on what's going on?"], "usr-2": ["I was able to get this issue resolved, by adding a grub bootloader to my image and changing the partition layout table from GPT to MBR"], "usr-3": ["closing"]}, "Question": "I am trying to import a raw image. The partition layout of the raw image are as follows: Number Start (sector) End (sector) Size Code Name 1 2048 1050623 512.0 MiB EF00 boot_raid_1 2 1050624 1071103 10.0 MiB EF02 boot_raid_2 3 1071104 22042623 10.0 GiB 8300 root_raid_1 4 22042624 22063103 10.0 MiB 8300 root_raid_2 5 22063104 38840319 8.0 GiB 8300 config_raid 6 38840320 134217694 45.5 GiB 8300 local_raid The import is failing with the following: { 'ImportImageTasks': [ { 'Status': 'deleted', 'SnapshotDetails': [ { 'UserBucket': { 'S3Bucket': 'dateravms', 'S3Key': 'DateraOS-sda.raw' }, 'DiskImageSize': 68719476736.0, 'Description': 'Datera raw', 'Format': 'RAW' } ], 'Description': 'Datera raw', 'StatusMessage': 'ClientError: No valid partitions. Not a valid volume.', 'ImportTaskId': 'import-ami-fgwkj0j7' } ] } Any suggestions on what's going on?", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249538&tstart=75"},
{"Answers": {"usr-1": ["I'm attempting to enable EC2 instance recovery on an m4.large instance in us-west-2 (i-0cc1261526dd0d30e). When I try to use Create Alarm to add this, the \"Recover this instance\" option is grayed out. The other 3 options are all available. Since this is an m4.large, I know there is not an issue with having instance store volumes preventing this, but I'm at a loss for what else could be causing this problem. I have been able to add this feature to other instances in us-west-2. This instance has an IAM role, but none of the policies for that role are denying any access. Any reply would be greatly appreciated!"], "usr-2": ["Hello, We took a look at your instance i-0cc1261526dd0d30e and we see that this instance has been terminated. Terminated instances cannot be recovered and we will be unable to troubleshoot this further because of this. Please refer to our guide for Troubleshooting Instance Recovery Failures: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/TroubleshootingInstanceRecovery.html and do let us know if you have issues with enabling EC2 instance recovery on a running instance."], "usr-3": ["Thanks very much for the reply. I terminated that instance after a few days, thinking I wasn't going to get a response. i-03801825e55a6133d is a similar m4 instance that also allows stopping, starting, terminating, but not recovering. Would it be possible to look at that instance and hopefully determine why \"Recover this instance\" is greyed out? Thanks!"], "usr-4": ["Hello, I can see that your instance i-03801825e55a6133d has two instance store volumes attached. Per our doc [1], having attached instance store storage is an unsupported configuration for automatic instance recovery. I hope that helps? For more information about instance recovery, please see [2]. Thank you for using AWS! [1] http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/TroubleshootingInstanceRecovery.html [2] https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-recover.html"], "usr-5": ["Thanks so much for the reply. I'm still a little confused, because my understanding is that an m4.large can only have EBS volumes, and I only see a single EBS volume using 'aws ec2 describe-instances --instance-ids i-03801825e55a6133d' or via the console. \"BlockDeviceMappings\": [ { \"DeviceName\": \"/dev/sda1\", \"Ebs\": { \"Status\": \"attached\", \"DeleteOnTermination\": true, \"VolumeId\": \"vol-000d1424ba1dfaaad\", \"AttachTime\": \"2017-02-17T19:56:51.000Z\" } } ], Is there some other place you are seeing ephemeral drives on this instance? Thanks! Edited by: chss on Mar 8, 2017 2:58 PM"], "usr-6": ["Our problem turned out to be that the base AMI we were using, an Ubuntu 14.04 AMI, includes metadata for ephemeral0 and ephemeral1. This is visible by looking at the AMI in console. For example, ami-5e63d13e in us-west-2 shows these block devices: /dev/sda1=snap-0525e650246827d18:8:true:gp2, /dev/sdb=ephemeral0, /dev/sdc=ephemeral1 When creating new AMIs from this base AMI using either Packer or knife-ec2, that metadata was preserved in the new AMIs, even when using an instance type that does not support ephemeral drives. When creating new AMIs from this base AMI in the console for an m4 or c4 instance type, that metadata is removed. So it appears that any process that uses the AWS APIs improperly preserves the ephemeral block device metadata, even for instance types where those devices are not supported. Until that issue is fixed, we will use the console to create AMIs that are clean of the ephemeral drives so we can then enable EC2 Recovery on instances launched from those AMIs."]}, "Question": "I'm attempting to enable EC2 instance recovery on an m4.large instance in us-west-2 (i-0cc1261526dd0d30e). When I try to use Create Alarm to add this, the 'Recover this instance' option is grayed out. The other 3 options are all available. Since this is an m4.large, I know there is not an issue with having instance store volumes preventing this, but I'm at a loss for what else could be causing this problem. I have been able to add this feature to other instances in us-west-2. This instance has an IAM role, but none of the policies for that role are denying any access. Any reply would be greatly appreciated!", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249528&tstart=75"},
{"Answers": {"usr-1": ["Hi people, I'm new to AWS, in the next weeks I'll have to export a VM to AWS to one of my customers and I'm doing a test with a VM with windows. I can't fix the following error: ec2-import-instance D:\\VirtualMachines\\lab1VPN-disk1.vmdk -f vmdk -a x86_64 -b silicitt -o \"AWSAccesskey\" -w \"AWSSecretAccesskey\" -O \"AWSAccesskey\" -W \"AWSSecretAccesskey\" -p windows Requesting volume size: 60 GB ERROR: Unable to create signed manifest URL. Cannot access/create bucket: silicitt : com.amazonaws.services.s3.model.AmazonS3Exception: Bad Request (Service: Amazon S3; Status Code: 400; Error Code: 400 Bad Request; Request ID: F47AB8D914ACAD91), S3 Extended Request ID: F0Sj1qYdnYgz1tvS5tL1/nFO9ZhAbpcVSCQwKXD2h3A7g7jTsBga3qRObX9Xj72nrJKUSzGZrsY= The bucket is \"silicitt\" and the user is \"silici\" I've added the following policy on the user permission: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"s3:ListAllMyBuckets\" ], \"Resource\": \"*\" }, { \"Effect\": \"Allow\", \"Action\": [ \"s3:CreateBucket\", \"s3:DeleteBucket\", \"s3:DeleteObject\", \"s3:GetBucketLocation\", \"s3:GetObject\", \"s3:ListBucket\", \"s3:PutObject\" ], \"Resource\": [ \"arn:aws:s3:::silicitt\", \"arn:aws:s3:::silicitt/*\" ] }, { \"Effect\": \"Allow\", \"Action\": [ \"iam:CreateRole\", \"iam:PutRolePolicy\" ], \"Resource\": \"*\" }, { \"Effect\": \"Allow\", \"Action\": [ \"ec2:CancelConversionTask\", \"ec2:CancelExportTask\", \"ec2:CreateImage\", \"ec2:CreateInstanceExportTask\", \"ec2:CreateTags\", \"ec2:DeleteTags\", \"ec2:DescribeConversionTasks\", \"ec2:DescribeExportTasks\", \"ec2:DescribeInstanceAttribute\", \"ec2:DescribeInstanceStatus\", \"ec2:DescribeInstances\", \"ec2:DescribeTags\", \"ec2:ImportInstance\", \"ec2:ImportVolume\", \"ec2:StartInstances\", \"ec2:StopInstances\", \"ec2:TerminateInstances\", \"ec2:ImportImage\", \"ec2:ImportSnapshot\", \"ec2:DescribeImportImageTasks\", \"ec2:DescribeImportSnapshotTasks\", \"ec2:CancelImportTask\" ], \"Resource\": \"*\" } ] } but if I logon to the AWS portal on S3, I can create folders and file with user silici, so seems to not be a problem of permissions. Many thanks for your help!!!!"], "usr-2": ["Hi , I Tried to Create Bucket \"silicitt\" , It Already Exists. shouldnt S3 Bucket name be Unique? Is it Already Created by You or someone Else may have Taken it. Can you please check."], "usr-3": ["Hello, I created myself this bucket on the AWS website, isn't that correct? I'm new to AWS, I thought that have to create the bucket manually before. Thanks to clarify Best regards Edited by: ricardsantacreu on Feb 20, 2017 12:02 AM"]}, "Question": "Hi people, I'm new to AWS, in the next weeks I'll have to export a VM to AWS to one of my customers and I'm doing a test with a VM with windows. I can't fix the following error: ec2-import-instance D:\\VirtualMachines\\lab1VPN-disk1.vmdk -f vmdk -a x86_64 -b silicitt -o 'AWSAccesskey' -w 'AWSSecretAccesskey' -O 'AWSAccesskey' -W 'AWSSecretAccesskey' -p windows Requesting volume size: 60 GB ERROR: Unable to create signed manifest URL. Cannot access/create bucket: silicitt : com.amazonaws.services.s3.model.AmazonS3Exception: Bad Request (Service: Amazon S3; Status Code: 400; Error Code: 400 Bad Request; Request ID: F47AB8D914ACAD91), S3 Extended Request ID: F0Sj1qYdnYgz1tvS5tL1/nFO9ZhAbpcVSCQwKXD2h3A7g7jTsBga3qRObX9Xj72nrJKUSzGZrsY= The bucket is 'silicitt' and the user is 'silici' I've added the following policy on the user permission: { 'Version': '2012-10-17', 'Statement': [ { 'Effect': 'Allow', 'Action': [ 's3:ListAllMyBuckets' ], 'Resource': '-' }, { 'Effect': 'Allow', 'Action': [ 's3:CreateBucket', 's3:DeleteBucket', 's3:DeleteObject', 's3:GetBucketLocation', 's3:GetObject', 's3:ListBucket', 's3:PutObject' ], 'Resource': [ 'arn:aws:s3:::silicitt', 'arn:aws:s3:::silicitt/-' ] }, { 'Effect': 'Allow', 'Action': [ 'iam:CreateRole', 'iam:PutRolePolicy' ], 'Resource': '-' }, { 'Effect': 'Allow', 'Action': [ 'ec2:CancelConversionTask', 'ec2:CancelExportTask', 'ec2:CreateImage', 'ec2:CreateInstanceExportTask', 'ec2:CreateTags', 'ec2:DeleteTags', 'ec2:DescribeConversionTasks', 'ec2:DescribeExportTasks', 'ec2:DescribeInstanceAttribute', 'ec2:DescribeInstanceStatus', 'ec2:DescribeInstances', 'ec2:DescribeTags', 'ec2:ImportInstance', 'ec2:ImportVolume', 'ec2:StartInstances', 'ec2:StopInstances', 'ec2:TerminateInstances', 'ec2:ImportImage', 'ec2:ImportSnapshot', 'ec2:DescribeImportImageTasks', 'ec2:DescribeImportSnapshotTasks', 'ec2:CancelImportTask' ], 'Resource': '-' } ] } but if I logon to the AWS portal on S3, I can create folders and file with user silici, so seems to not be a problem of permissions. Many thanks for your help!!!!", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249642&tstart=75"},
{"Answers": {"usr-1": ["Hi all. I need to increase my ec2 instance limit from lets say 20 to 40. But when i go to the support center to create a service limit increase case it asks me to select instance type and set new limit for it. Is there some way i can specify that the total instances do not increase 40 for all the types combined? Otherwise if i set a limit for a particular instance type then how does that work? Is it calculated after the default 20 instance limit is reached or what? Looking for details. Regards"], "usr-2": ["Hello, Thanks for your post. I have sent you a private message about it, I need some clarification. Thanks!"], "usr-3": ["So, We opened a case and in the details we explained that we need to set an over all limit of t2 instances to x (collectively) and it was upgraded. My only suggestion would be to create this option in the UI itself"]}, "Question": "Hi all. I need to increase my ec2 instance limit from lets say 20 to 40. But when i go to the support center to create a service limit increase case it asks me to select instance type and set new limit for it. Is there some way i can specify that the total instances do not increase 40 for all the types combined? Otherwise if i set a limit for a particular instance type then how does that work? Is it calculated after the default 20 instance limit is reached or what? Looking for details. Regards", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249668&tstart=75"},
{"Answers": {"usr-1": ["Hi! We have basic support plan and can not request ELB prewarming thru AWS Console. Can someone from AWS assist with ELB prewarm? Thank you!"], "usr-2": ["Did not get any answer in a time..."]}, "Question": "Hi! We have basic support plan and can not request ELB prewarming thru AWS Console. Can someone from AWS assist with ELB prewarm? Thank you!", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249754&tstart=75"},
{"Answers": {"usr-1": ["I have an instance of EC2. I am trying to use the command in one of my php documents: imagecreatefromjpeg but it fails. While trying to use this code: wget http://us1.php.net/distributions/php-5.5.10.tar.gz -O php.tar.gz tar -xvf php.tar.gz cd php-5.5.10 yum -y install libxml2-devel libmcrypt-devel libpng-devel ./configure --with-config-file-path=/etc --with-config-file-scan-dir=/etc/php.d --with-apxs2 --with-mysql --with-mysqli --with-zlib --with-curl --with-libdir=lib --with-openssl --with-pdo-mysql --with-mcrypt --with-pcre-regex --enable-zip --with-gd --enable-mbstring --with-jpeg-dir=/usr/lib make clean make make install My install fails and says Sorry, I cannot run apxs.. Possible reasons follow: 1. Perl is not installed 2. apxs was not found. Try to pass the path using --with-apxs2=/path/to/apxs 3. Apache was not built using --enable-so (the apxs usage page is displayed) I'm just trying to install basic php image processing. Help please."], "usr-2": ["This really has nothing to do with AWS. You're better off asking in a PHP forum. BUT, you really probably want to install PHP and all of its dependencies through your package manager (yum). There's no reason to build PHP (or most anything) from source. Just do 'yum install php' or 'yum install php-gd' or whatever (those are not the actual package names, I'll leave finding the actual names as an exercise for you)."]}, "Question": "I have an instance of EC2. I am trying to use the command in one of my php documents: imagecreatefromjpeg but it fails. While trying to use this code: wget http://us1.php.net/distributions/php-5.5.10.tar.gz -O php.tar.gz tar -xvf php.tar.gz cd php-5.5.10 yum -y install libxml2-devel libmcrypt-devel libpng-devel ./configure --with-config-file-path=/etc --with-config-file-scan-dir=/etc/php.d --with-apxs2 --with-mysql --with-mysqli --with-zlib --with-curl --with-libdir=lib --with-openssl --with-pdo-mysql --with-mcrypt --with-pcre-regex --enable-zip --with-gd --enable-mbstring --with-jpeg-dir=/usr/lib make clean make make install My install fails and says Sorry, I cannot run apxs.. Possible reasons follow: 1. Perl is not installed 2. apxs was not found. Try to pass the path using --with-apxs2=/path/to/apxs 3. Apache was not built using --enable-so (the apxs usage page is displayed) I'm just trying to install basic php image processing. Help please.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249946&tstart=75"},
{"Answers": {"usr-1": ["Hello, Have tried and failed to start instance i-463e2fd5 several times now. One of the attached EBS volumes (vol-9474fa05) was showing unusually high (constant 20) queue length starting at 16:53 UTC. I am seeing reports of degraded EBS performance; is this related, and is there an ETA for resolution? Thanks!"], "usr-2": ["Same issue here, us-east-1d. Instance was having issues, stopped it, now can't start. Just praying Amazon fixes it quickly."], "usr-3": ["Confirmed, just have our instance+volume back up and running. Time to look into DFS and more fault tolerance."]}, "Question": "Hello, Have tried and failed to start instance i-463e2fd5 several times now. One of the attached EBS volumes (vol-9474fa05) was showing unusually high (constant 20) queue length starting at 16:53 UTC. I am seeing reports of degraded EBS performance; is this related, and is there an ETA for resolution? Thanks!", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249991&tstart=75"},
{"Answers": {"usr-1": ["I've been reading the AWS article here: https://aws.amazon.com/premiumsupport/knowledge-center/troubleshoot-remote-desktop-connection-ec2-windows/ This article pretty exactly describes my problem (can't RDP to windows ec2 instance from mac). This article lists possible problem and their solutions. The second problem listed is: Client Windows Firewall rules that do not allow outbound connections over RDP. And the solution says \"In Control Panel, open ...\". Since I can't access the windows machine, how am I supposed to access the control panel? Am I misunderstanding something? Is there another way to make sure RDP is enabled on an ec2 windows machine? this is the AMI I am using: Windows_Server-2008-R2_SP1-English-64Bit-Base-2017.01.20 (ami-d0ac46c6) Thanks for any help. Paul Edited by: jpaulny on Feb 21, 2017 10:07 AM"], "usr-2": ["Okay, take it a step back. The article is referring to Windows Control Panel, but you are on Mac.... So it wont help. RDP is enabled on EC2, ensure that your security group is configured to allow RDP to your IP on port 3389. Also, make sure that the instance has access to the Interwebs. And a Public IP. Are you using the latest RDC app? The old one is flaky IMO."], "usr-3": ["Yes I'm using the latest RDP, app just downloaded it form the apple store. I see so the instructions were meant for the local machine, not the ec2 instance, that makes sense now. My security group is configured correctly. How do I check the ec2 instance has access to the internet? I tried opening port 80 to my ip but when I put the public ip in a browser it I get \"failed to open page\". Should I expect to see a page on windows server from the public IP? Thx."], "usr-4": ["Are you using Default VPC (172.31.0.0/16)? Yes, you should be able to see the IIS welcome screen by default. To see if it will work at all, have you tried opening ports 80 and 3389 to Anywhere (0.0.0.0/0)?"], "usr-5": ["No my VPC is not Default VPC and it uses 172.30.0.0/16. I don't have a VPC that is Default, not sure why. Good to know I should be seeing the IIS welcome screen, that points to connectivity I think. Haven't tried opening the ports to Anywhere, just to my own ip address. Don't see why that would make a difference but I'll try it. Edited by: jpaulny on Feb 21, 2017 7:50 PM"], "usr-6": ["Found this: \"If you created your AWS account before December 4th, 2013, your account may have never had a default VPC.\" this applies to me"], "usr-7": ["Okay, that's one thing checked off the list. It does suggest you need to look at your subnets and make sure you have an IGW attached to the VPC with a route to it for all non-local traffic. Have you tried creating your instance in Classic EC2?"], "usr-8": ["Re Classic EC2, that option is greyed out for the t2.micro instance type I have been trying, so I tried an m3.medium, and I was able to launch it into Classic EC2, and voila, I'm in with RDP! I'll have to figure out this VPC stuff (but later , this is a short term project so I don't mind paying a bit more for the medium. Thank you so much for your help and quick replies! Paul"]}, "Question": "I've been reading the AWS article here: https://aws.amazon.com/premiumsupport/knowledge-center/troubleshoot-remote-desktop-connection-ec2-windows/ This article pretty exactly describes my problem (can't RDP to windows ec2 instance from mac). This article lists possible problem and their solutions. The second problem listed is: Client Windows Firewall rules that do not allow outbound connections over RDP. And the solution says 'In Control Panel, open ...'. Since I can't access the windows machine, how am I supposed to access the control panel? Am I misunderstanding something? Is there another way to make sure RDP is enabled on an ec2 windows machine? this is the AMI I am using: Windows_Server-2008-R2_SP1-English-64Bit-Base-2017.01.20 (ami-d0ac46c6) Thanks for any help. Paul Edited by: jpaulny on Feb 21, 2017 10:07 AM", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249801&tstart=75"},
{"Answers": {"usr-1": ["I requested an EC2 instance limit increase over 12 hours ago for an additional 6 instances via the support form in the console. I know it says it takes up to 24 hours to respond to these requests but I'm just wondering how long it usually takes for someone on the developer support plan to get their limit increased. Also, I read online that I can request they contact me via phone on the increase request page and they call you within 15 mins. Can anyone confirm this? I would like to know if it's worth it to close my current request and make a new one using the phone option. Thanks, Juan"]}, "Question": "I requested an EC2 instance limit increase over 12 hours ago for an additional 6 instances via the support form in the console. I know it says it takes up to 24 hours to respond to these requests but I'm just wondering how long it usually takes for someone on the developer support plan to get their limit increased. Also, I read online that I can request they contact me via phone on the increase request page and they call you within 15 mins. Can anyone confirm this? I would like to know if it's worth it to close my current request and make a new one using the phone option. Thanks, Juan", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250059&tstart=75"},
{"Answers": {"usr-1": ["Hello, I accidentally deleted the key pairs from the AWS console. I then realised that I'm able to generate new one which normally would grant me access back to the ssh. I generated a new key and the pem download triggered automatically. However using that new key doesn't allow me to access my console. Anyone knows what I missing in this process ? I can't really shutdown/restart the instance as it is a prod website and bringing downtime will affect the business. Thanks,"], "usr-2": ["You will need to 'inform' your instance of the new keypair. It's not a difficult task but you will need to take the instance offline to do so. You will need to import the key signature into the authorized keys folder. The simplest thing for you to do is: 1. Backup your instance 2. Launch a new instance (blank instance, doesn't matter) with the new keypair 3. Attach & Mount the volume from your primary instance on your new instance - you need access to the file system 4. Copy ~/.ssh/authorized_keys to YOURMOUNTPOINT/home/ubuntu/.ssh/authorized_keys - Note that if you are using one of the \"other\" operating systems you will need to change the admin account as needed - ec2-user or whatever 5. umount and detach the volume, attach it back to /dev/sda1 on your primary instance 6. Launch the instance and log in with your new keypair 7. Terminate your new instance 8. Have a cup of tea and pat yourself on the back. As you mentioned you can't have downtime... Consider that issue for a second and wonder why, if it's so important, you don't have capacity for it to have an unknown issue. Your best bet is an ELB in front of the server, then you can change the web server whenever you need to. Unless if your web server is also your DB server. In which case spend some time and money and get it sorted out. For your immediate issue, if you don't need to get on the server then leave it until you have some redundancy in place. If you do need to get on the server then arrange some downtime. Edited by: thisisthetechie on Feb 20, 2017 11:44 AM Edited by: thisisthetechie on Feb 20, 2017 11:46 AM"], "usr-3": ["Thank you for your quick reply. Will this imply extra costs ? I'm also not really oriented administration of systems, but I can understand all the steps in your post, I'm just curious if anything goes wrong I can just mount back the volume on my previous instance and it will be back to normal, right ?"], "usr-4": ["That's correct. You are basically just taking the hard drive out of the computer, putting it into another computer and making a change to a text file, then putting the drive back. There will be additional costs while you do the work (you are charged per hour compute time, so potentially you will get charged an extra 3 hours worth of EC2 compute time for the instance type of your choosing... Or thereabouts). If you add an ELB the cost is negligable, but the benefit outweighs the cost from an ops perspective. So if you want to minimise downtime, take a snapshot of the volume you want to update and launch that as a new volume (in the same AZ as your server) and then launch a new instance (in the same AZ as your server) and do the work. Then you turn off the server, swap the drives, turn it back on. If it doesn't work you repeat to reverse."], "usr-5": ["Thanks for the clear instructions ! problem solved and by checking the billing I didn't see any raise and website was only down for couple minutes. Cheers"], "usr-6": ["Good Work. Did you remember the cup of tea, was an important step!"]}, "Question": "Hello, I accidentally deleted the key pairs from the AWS console. I then realised that I'm able to generate new one which normally would grant me access back to the ssh. I generated a new key and the pem download triggered automatically. However using that new key doesn't allow me to access my console. Anyone knows what I missing in this process ? I can't really shutdown/restart the instance as it is a prod website and bringing downtime will affect the business. Thanks,", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=249609&tstart=75"},
{"Answers": {"usr-1": ["Tried stopping the instance and then force stopping it twice. It's still stuck in the stopping state (i-b93c69c3)"], "usr-2": ["It stopped just after posting this thread."]}, "Question": "Tried stopping the instance and then force stopping it twice. It's still stuck in the stopping state (i-b93c69c3)", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250101&tstart=75"},
{"Answers": {"usr-1": ["We can't reach the instance. Trying to stop it. have tried reboot/stop/force stop for 40 minutes. None works. Please help us to stop the instance. It affects our application. thanks,"], "usr-2": ["finally, after 1 hour and 10 minutes, the instance is stopped. If someone has helped us, thanks!"]}, "Question": "We can't reach the instance. Trying to stop it. have tried reboot/stop/force stop for 40 minutes. None works. Please help us to stop the instance. It affects our application. thanks,", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250111&tstart=75"},
{"Answers": {"usr-1": ["I was hoping to migrate a project over from an r3 instance to an i3 instance but when I try to access some files that I store on the new NVMe storage I am getting an \"Input/output error\". The files I am trying to access when I get the errors are larger than 100MB."], "usr-2": ["I'm seeing the same thing on four different instances I've started -- strangely I have one which is not showing these symptoms as well. $ uname -a Linux prod-db8 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux http:// 637.771404 blk_update_request: I/O error, dev nvme0n1, sector 2903658768 http:// 637.777122 Buffer I/O error on dev nvme0n1, logical block 362874338, lost async page write http:// 637.783738 Buffer I/O error on dev nvme0n1, logical block 362874339, lost async page write http:// 637.790257 Buffer I/O error on dev nvme0n1, logical block 362874340, lost async page write http:// 637.796905 Buffer I/O error on dev nvme0n1, logical block 362874341, lost async page write http:// 637.803562 Buffer I/O error on dev nvme0n1, logical block 362874342, lost async page write http:// 637.810209 Buffer I/O error on dev nvme0n1, logical block 362874343, lost async page write http:// 637.816915 Buffer I/O error on dev nvme0n1, logical block 362874344, lost async page write http:// 637.823599 Buffer I/O error on dev nvme0n1, logical block 362874345, lost async page write http:// 637.830210 Buffer I/O error on dev nvme0n1, logical block 362874346, lost async page write http:// 637.836862 Buffer I/O error on dev nvme0n1, logical block 362874347, lost async page write http:// 946.211647 blk_update_request: I/O error, dev nvme0n1, sector 2994972408 http:// 946.215971 buffer_io_error: 102391 callbacks suppressed http:// 946.215975 Buffer I/O error on dev nvme0n1, logical block 374368959, lost async page write http:// 946.221139 Buffer I/O error on dev nvme0n1, logical block 374368960, lost async page write http:// 946.226724 Buffer I/O error on dev nvme0n1, logical block 374368961, lost async page write http:// 946.232323 Buffer I/O error on dev nvme0n1, logical block 374368962, lost async page write http:// 946.237891 Buffer I/O error on dev nvme0n1, logical block 374368963, lost async page write http:// 946.243339 Buffer I/O error on dev nvme0n1, logical block 374368964, lost async page write http:// 946.248570 Buffer I/O error on dev nvme0n1, logical block 374368965, lost async page write Edited by: mattbillenstein on Feb 26, 2017 6:46 PM"], "usr-3": ["Looks like the ubuntu guys are on it: https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1668129?comments=all"], "usr-4": ["Workaround available here: https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1668129/comments/29 Will be fixed in the next AMI update."]}, "Question": "I was hoping to migrate a project over from an r3 instance to an i3 instance but when I try to access some files that I store on the new NVMe storage I am getting an 'Input/output error'. The files I am trying to access when I get the errors are larger than 100MB.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250086&tstart=75"},
{"Answers": {"usr-1": ["Basically subj. Dualstack ELB falcon-stage-new-1293399935.eu-central-1.elb.amazonaws.com or falcon-stage-1084330696.eu-central-1.elb.amazonaws.com both timeout on IPv6 requests. Tried HTTP and HTTPS. IPv4 works ok. Please advise."], "usr-2": ["Sorry, turns out I used a bad IPv6 validation service. All this time it was working."]}, "Question": "Basically subj. Dualstack ELB falcon-stage-new-1293399935.eu-central-1.elb.amazonaws.com or falcon-stage-1084330696.eu-central-1.elb.amazonaws.com both timeout on IPv6 requests. Tried HTTP and HTTPS. IPv4 works ok. Please advise.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250137&tstart=75"},
{"Answers": {"usr-1": ["I have a simple application architecture: I have a flask app running on an EC2 server talking with a postgresql database running on an RDS instance. The EC2 instance and the RDS instance are deployed in the same VPC and are part of the same security group. The RDS instance is not publicly accessible. I had assumed that since the RDS and EC2 instances were part of the same security group, it was not necessary to open port 5432 (Postgresql port) on the EC2 instance in order to things to work. Currently everything is running fine, but I have port 5432 on the EC2 instance open to all IP addresses. I don't feel so comfortable with this from a security perspective and I would prefer to limit the port to only being open to IP addresses belonging to AWS (or some other restricted set of IP addresses). Is this possible? If so, how do I implement it?"], "usr-2": ["You can specify a security group as the \"Source\" instead of an IP address. Start typing the id or name of the current security group."]}, "Question": "I have a simple application architecture: I have a flask app running on an EC2 server talking with a postgresql database running on an RDS instance. The EC2 instance and the RDS instance are deployed in the same VPC and are part of the same security group. The RDS instance is not publicly accessible. I had assumed that since the RDS and EC2 instances were part of the same security group, it was not necessary to open port 5432 (Postgresql port) on the EC2 instance in order to things to work. Currently everything is running fine, but I have port 5432 on the EC2 instance open to all IP addresses. I don't feel so comfortable with this from a security perspective and I would prefer to limit the port to only being open to IP addresses belonging to AWS (or some other restricted set of IP addresses). Is this possible? If so, how do I implement it?", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250156&tstart=50"},
{"Answers": {"usr-1": ["I have been experiencing random instance fails for brief periods in the following instances: i-b9cfd4fb i-22a5ac88 No trace of any unusual activity or events on system logs, and the instance failures resolve themselves after a while. How can I troubleshoot this?"], "usr-2": ["Hello, Thanks for your post. I have looked at the underlying hardware, they are in a good status, but there are a few instance status checks failure. Usually this would need your involvement to look at the system logs to investigate why the instance stops responding. [1] The following are examples of problems that can cause instance status checks to fail: Failed system status checks Incorrect networking or startup configuration Exhausted memory Corrupted file system Incompatible kernel Thanks! [1]. http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-system-instance-status-check.html"]}, "Question": "I have been experiencing random instance fails for brief periods in the following instances: i-b9cfd4fb i-22a5ac88 No trace of any unusual activity or events on system logs, and the instance failures resolve themselves after a while. How can I troubleshoot this?", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250159&tstart=50"},
{"Answers": {"usr-1": ["us-east-1 I'm only running 14 instances for one thing. Anybody else seeing this sort of problem ? Any work arounds other than waiting for AWS support ?"], "usr-2": ["I'm past this error and now launch is going into pending state. That seems tied into S3 problem."], "usr-3": ["Hello, S3 issues were causing degradation and issues with other services. The latest information on this can be found here: http://status.aws.amazon.com/ We apologize for any inconvenience caused. Regards, Nick"]}, "Question": "us-east-1 I'm only running 14 instances for one thing. Anybody else seeing this sort of problem ? Any work arounds other than waiting for AWS support ?", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250280&tstart=50"},
{"Answers": {"usr-1": ["Hi, Instance ID i-08a284acade4ec8e5 is unreachable for over 30 mins. I tried to stop it, but still hanging into a \"stopping\" state. Can you please advise? Edited by: pepper on Feb 28, 2017 10:41 PM"]}, "Question": "Hi, Instance ID i-08a284acade4ec8e5 is unreachable for over 30 mins. I tried to stop it, but still hanging into a 'stopping' state. Can you please advise? Edited by: pepper on Feb 28, 2017 10:41 PM", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250413&tstart=50"},
{"Answers": {"usr-1": ["I have an instance that was running fine until all of a sudden it became incommunicado. Following the troublshooting guide, I have tried the following without success: 1. stop and start numerous times, 2. tried creating an AMI, 3. tried taking a snapshot of its volume. The id of the instance is: i-0b5e6b70a3cba1390 Thanks."], "usr-2": ["Hi, This appears to be related to the issues that have been ongoing in the N. Virginia region today. Snapshots and ebs performance have been impacted (along with other services) in relation to what has been going on. Please have a look here: https://status.aws.amazon.com https://phd.aws.amazon.com/phd/home#/dashboard/open-issues for more detailed information on what has been going on."], "usr-3": ["Thanks. I did see those alerts for S3 issues, but since I don't use that service explicitly, I didn't think that impacted me considering I was only having the issue with one instance (which, coincidentally, I had just spun up the night before) out of 15."]}, "Question": "I have an instance that was running fine until all of a sudden it became incommunicado. Following the troublshooting guide, I have tried the following without success: 1. stop and start numerous times, 2. tried creating an AMI, 3. tried taking a snapshot of its volume. The id of the instance is: i-0b5e6b70a3cba1390 Thanks.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250328&tstart=50"},
{"Answers": {"usr-1": ["Hi, I have the following aws cli command running as a backup to s3: aws s3 sync 'source' 'destination' --delete -sse AES256 Is there a way to only place a delete marker in S3 instead of actually deleting the file completely? I would like S3 Lifecycle to take control when an object is removed but the s3 sync completely removes the object. Edited by: Ric on Mar 1, 2017 9:57 AM"], "usr-2": ["Removed the --delete switch and made use of lifecyle expiration/delete instead"]}, "Question": "Hi, I have the following aws cli command running as a backup to s3: aws s3 sync 'source' 'destination' --delete -sse AES256 Is there a way to only place a delete marker in S3 instead of actually deleting the file completely? I would like S3 Lifecycle to take control when an object is removed but the s3 sync completely removes the object. Edited by: Ric on Mar 1, 2017 9:57 AM", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250416&tstart=50"},
{"Answers": {"usr-1": ["I have 2 Linux (amazon Linux, Ubuntu) servers now, that I cannot get into using putty.exe The both give me a connection refused. One of the servers is a Linux DB server, and the app server that connects to it, cannot connect and I also cannot connect to the PostgreSQL DB via PgAdminIII."], "usr-2": ["Hello, Please verify security groups, network ACLs, and route tables in your VPC. Additionally verify the username (Ubuntu AMI username should be 'ubuntu') and pem key you're connecting with. Regards, Nick"], "usr-3": ["Thank You Nick, Everything in security groups, username, and pem seem to be in order. I do not know how to check the network ACLs, and route tables in my VPC. I have also tried to create an AMI from my instance and launch that to see if it helps, but the issue persists in the new instance. I was able to connect to the old instance before, but all of a sudden I am not. I looked at the system logs and found this: \"The disk drive for /data is not ready yet or not present. keys:Continue to wait, or Press S to skip mounting or M for manual recovery\" Could this be the issue?"], "usr-4": ["Yes that would be the issue for sure. The machine is stuck because he has an external disk volume mounting on /data in /etc/fstab and there's a problem with it. Apparently, still a lot of issues with EC2 and EBS stuff as an aftershock from S3 or perhaps a wider power issue in a us-east-1 AZ."], "usr-5": ["Thanks Nick. The connection issue that started occurring today with my DB on the EC2 has indeed corrected itself, however the issue with the server that has the mount problem is a few days old. Is this something that may remedy itself, if Amazon is experiencing issues? If not, any suggestions for me to fix it from my side? Matt"], "usr-6": ["Sorry for calling you Nick before bamthin Your assertion made me go back and look at the mounts again. Indeed, this instance was created from an AMI that had an extra EBS attached. That EBS was no longer attached. After I reattached the EBS I was able to connect. Thanks!"]}, "Question": "I have 2 Linux (amazon Linux, Ubuntu) servers now, that I cannot get into using putty.exe The both give me a connection refused. One of the servers is a Linux DB server, and the app server that connects to it, cannot connect and I also cannot connect to the PostgreSQL DB via PgAdminIII.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250351&tstart=50"},
{"Answers": {"usr-1": ["i'm trying to distribute a server on the instance and connect it by tcp from outside. But i found i can't connect it through the public ip by many ways, so i use rdt to use instance to ping the instance address, I can ping the private ip, but public ip can't do, and i also can't ping public ip from outside, can't understand. instance use windows server, firewall already closed. safty group already tried different rules, specific tcp port to all connections and all tcp port to all connection both tried. ICMP rules open to all connections. the problem is really weird, any clues to solve this? my instance id: i-04ff7270c90cf740a"], "usr-2": ["found the problem, the ICMP Rule need both echo request an echo reply"]}, "Question": "i'm trying to distribute a server on the instance and connect it by tcp from outside. But i found i can't connect it through the public ip by many ways, so i use rdt to use instance to ping the instance address, I can ping the private ip, but public ip can't do, and i also can't ping public ip from outside , can't understand. instance use windows server, firewall already closed. safty group already tried different rules, specific tcp port to all connections and all tcp port to all connection both tried. ICMP rules open to all connections. the problem is really weird, any clues to solve this? my instance id: i-04ff7270c90cf740a", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250444&tstart=50"},
{"Answers": {"usr-1": ["Hello, Our IP address was connecting initially, and just recently stopped resolving. I messed around with the security groups as I was trying to clean up instances, but I'm wondering if I might've ruined the connection with that. Files are available on the server to access but I receive the ERR_CONNECTION_TIMED_OUT on attempt. We have an elastic IP on the instance. Any ideas or comments are completely appreciated, along with any resources. thank you!"], "usr-2": ["I found the solution, it was my security groups. I had a separate security group set up with the correct HTTP and HTTPS access, but this group was not applying to the instance itself. Once I added the correct access rules to the launch-wizard security group, I can access the server."]}, "Question": "Hello, Our IP address was connecting initially, and just recently stopped resolving. I messed around with the security groups as I was trying to clean up instances, but I'm wondering if I might've ruined the connection with that. Files are available on the server to access but I receive the ERR_CONNECTION_TIMED_OUT on attempt. We have an elastic IP on the instance. Any ideas or comments are completely appreciated, along with any resources. thank you!", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250454&tstart=50"},
{"Answers": {"usr-1": ["Please help, instance i-0c0cc7cb733485ca5"], "usr-2": ["Hello, We checked your instance for you and we can see that the instance is now terminated. Please let us know if your issue is resolved."], "usr-3": ["I confirmed the Instance is terminated, thank you."]}, "Question": "Please help, instance i-0c0cc7cb733485ca5", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250445&tstart=50"},
{"Answers": {"usr-1": ["Just started having this issue today ( 3/2/17 ). Any nslookup request to a U.S based domain from our instance in eu-central-1b times out. For example: nslookup succeeds with google.com, netflix.com. nslookup fails with jonkrusell.com Anything I should be looking at here?"], "usr-2": ["Instance Id is i-088ee9662a98e048f for any AWS reps that may want this."], "usr-3": ["3 hours later it has magically resolved itself. Not sure how to explain this to management."], "usr-4": ["Hello, We experienced an issue with some instances in the EU-Central-1 Region not able to resolve domains hosted by a single external provider. The issue has been resolved as of 8:27 AM PST. Lookups between resources within EC2 or to other providers were not impacted by this issue. Regards, Kay"], "usr-5": ["Thanks."]}, "Question": "Just started having this issue today ( 3/2/17 ). Any nslookup request to a U.S based domain from our instance in eu-central-1b times out. For example: nslookup succeeds with google.com, netflix.com. nslookup fails with jonkrusell.com Anything I should be looking at here?", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250480&tstart=50"},
{"Answers": {"usr-1": ["CVE 2017-6074 [1] \"allows local users to obtain root privileges or cause a denial of service\". The Amazon Linux AMI with kernel 4.4.44-39.55.amzn1.x86_64 appears to be vulnerable \u2014 the proof-of-concept causes my instance to immediately reboot. However, I do not see this CVE on the Amazon Linux AMI Security Center [2]. Will an update be provided for this kernel? Are there any other alternatives? I've temporarily switched to an Ubuntu-based AMI as an updated kernel is available there, but my tooling is focused on the Amazon Linux ecosystem, so I'd like to switch back as soon as possible. [1]: https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-6074 [2]: https://alas.aws.amazon.com/"], "usr-2": ["https://alas.aws.amazon.com/ALAS-2017-805.html appears to address this."]}, "Question": "CVE 2017-6074 [1] 'allows local users to obtain root privileges or cause a denial of service'. The Amazon Linux AMI with kernel 4.4.44-39.55.amzn1.x86_64 appears to be vulnerable - the proof-of-concept causes my instance to immediately reboot. However, I do not see this CVE on the Amazon Linux AMI Security Center [2]. Will an update be provided for this kernel? Are there any other alternatives? I've temporarily switched to an Ubuntu-based AMI as an updated kernel is available there, but my tooling is focused on the Amazon Linux ecosystem, so I'd like to switch back as soon as possible. [1]: https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-6074 [2]: https://alas.aws.amazon.com/", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250533&tstart=50"},
{"Answers": {"usr-1": ["In `/var/log/dmesg` this is present first http:// 4.514270 nvidia: module license 'NVIDIA' taints kernel. this is repeated multiple times http:// 4.514270 nvidia: module license 'NVIDIA' taints kernel. http:// 4.514271 Disabling lock debugging due to kernel taint http:// 4.520428 nvidia: module verification failed: signature and/or required key missing - tainting kernel http:// 4.550486 NVRM: The NVIDIA GRID K520 GPU installed in this system is http:// 4.550486 NVRM: supported through the NVIDIA 367.xx Legacy drivers. Please http:// 4.550486 NVRM: visit http://www.nvidia.com/object/unix.html for more http:// 4.550486 NVRM: information. The 375.26 NVIDIA driver will ignore http:// 4.550486 NVRM: this GPU. Continuing probe... http:// 4.550490 NVRM: The NVIDIA GRID K520 GPU installed in this system is http:// 4.550490 NVRM: supported through the NVIDIA 367.xx Legacy drivers. Please http:// 4.550490 NVRM: visit http://www.nvidia.com/object/unix.html for more http:// 4.550490 NVRM: information. The 375.26 NVIDIA driver will ignore http:// 4.550490 NVRM: this GPU. Continuing probe... Last line is http:// 6.088644 NVRM: No NVIDIA graphics adapter found! `lspci` has this 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC https://forums.aws.amazon.com/ (rev 02) 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA Natoma/Triton II 00:01.1 IDE interface: Intel Corporation 82371SB PIIX3 IDE Natoma/Triton II 00:01.3 Bridge: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 01) 00:02.0 VGA compatible controller: Cirrus Logic GD 5446 00:03.0 VGA compatible controller: NVIDIA Corporation GK104GL https://forums.aws.amazon.com/ (rev a1) 00:04.0 VGA compatible controller: NVIDIA Corporation GK104GL https://forums.aws.amazon.com/ (rev a1) 00:05.0 VGA compatible controller: NVIDIA Corporation GK104GL https://forums.aws.amazon.com/ (rev a1) 00:06.0 VGA compatible controller: NVIDIA Corporation GK104GL https://forums.aws.amazon.com/ (rev a1) 00:1f.0 Unassigned class https://forums.aws.amazon.com/: XenSource, Inc. Xen Platform Device (rev 01) Is this a virtualizing problem or some driver installation issue on my end. Any help debugging this would be appreciated."]}, "Question": "In `/var/log/dmesg` this is present first http:// 4.514270 nvidia: module license 'NVIDIA' taints kernel. this is repeated multiple times http:// 4.514270 nvidia: module license 'NVIDIA' taints kernel. http:// 4.514271 Disabling lock debugging due to kernel taint http:// 4.520428 nvidia: module verification failed: signature and/or required key missing - tainting kernel http:// 4.550486 NVRM: The NVIDIA GRID K520 GPU installed in this system is http:// 4.550486 NVRM: supported through the NVIDIA 367.xx Legacy drivers. Please http:// 4.550486 NVRM: visit http://www.nvidia.com/object/unix.html for more http:// 4.550486 NVRM: information. The 375.26 NVIDIA driver will ignore http:// 4.550486 NVRM: this GPU. Continuing probe... http:// 4.550490 NVRM: The NVIDIA GRID K520 GPU installed in this system is http:// 4.550490 NVRM: supported through the NVIDIA 367.xx Legacy drivers. Please http:// 4.550490 NVRM: visit http://www.nvidia.com/object/unix.html for more http:// 4.550490 NVRM: information. The 375.26 NVIDIA driver will ignore http:// 4.550490 NVRM: this GPU. Continuing probe... Last line is http:// 6.088644 NVRM: No NVIDIA graphics adapter found! `lspci` has this 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC https://forums.aws.amazon.com/ (rev 02) 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA Natoma/Triton II 00:01.1 IDE interface: Intel Corporation 82371SB PIIX3 IDE Natoma/Triton II 00:01.3 Bridge: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 01) 00:02.0 VGA compatible controller: Cirrus Logic GD 5446 00:03.0 VGA compatible controller: NVIDIA Corporation GK104GL https://forums.aws.amazon.com/ (rev a1) 00:04.0 VGA compatible controller: NVIDIA Corporation GK104GL https://forums.aws.amazon.com/ (rev a1) 00:05.0 VGA compatible controller: NVIDIA Corporation GK104GL https://forums.aws.amazon.com/ (rev a1) 00:06.0 VGA compatible controller: NVIDIA Corporation GK104GL https://forums.aws.amazon.com/ (rev a1) 00:1f.0 Unassigned class https://forums.aws.amazon.com/ : XenSource, Inc. Xen Platform Device (rev 01) Is this a virtualizing problem or some driver installation issue on my end. Any help debugging this would be appreciated.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250545&tstart=50"},
{"Answers": {"usr-1": ["When creating a new autoscaling group using Amazon ECS optimized linux AMI, there is a prompt saying \"This product requires advanced set up\" but that link is broken. https://us-west-2.console.aws.amazon.com/ec2/autoscaling/home?region=us-west-2#CreateLaunchConfiguration:CreationFlowType= https://aws.amazon.com/marketplace/ordering?ref=cns_1clkDis&productId=4ce33fd9-63ff-4f35-8d3a-939b641f1931 I was able to follow instructions from this blog post (http://www.ybrikman.com/writing/2015/11/11/running-docker-aws-ground-up/#deploying-docker-containers-on-ecs) but posting this issue here, just so that it can be fixed for future."]}, "Question": "When creating a new autoscaling group using Amazon ECS optimized linux AMI, there is a prompt saying 'This product requires advanced set up' but that link is broken. https://us-west-2.console.aws.amazon.com/ec2/autoscaling/home?region=us-west-2#CreateLaunchConfiguration:CreationFlowType= https://aws.amazon.com/marketplace/ordering?ref=cns_1clkDisandproductId=4ce33fd9-63ff-4f35-8d3a-939b641f1931 I was able to follow instructions from this blog post ( http://www.ybrikman.com/writing/2015/11/11/running-docker-aws-ground-up/#deploying-docker-containers-on-ecs ) but posting this issue here, just so that it can be fixed for future.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250570&tstart=50"},
{"Answers": {"usr-1": ["HI, I am very new to AWS and web-platforms. I managed to create the following AWS website.. After doing some reading.. I am pretty much stuck with one issue and hoping to get some help/advise from the experts.. My domain name: swagruha.co.uk. When try to access that domain, it resolves to actual public domain name of the physical EC2 machine - http://ec2-52-56-161-49.eu-west-2.compute.amazonaws.com/ . I am not sure if that's due to WordPress settings of this website Or if have done wrong setup within route 53. Below I have given the settings of 'A' and 'CANME' value types under route 53. swagruha.co.uk. - A - 52.56.161.49 www.swagruha.co.uk. - CNAME - swagruha.co.uk Please advise.. Thanks BSK"], "usr-2": ["Hello BSK, You Route53 settings and DNS routing are fine. It seems to me that you need to checkout - \"Site Address (URL)\" and \"WordPress Address (URL)\" and set your domain name appropriately. The link https://codex.wordpress.org/Changing_The_Site_URL should help you. Regards, Jayakrishnan L"], "usr-3": ["Hi, Thanks for the response.. yes.. It was resolved after setting th hostname as below.. sudo /opt/bitnami/apps/wordpress/bnconfig --machine_hostname swagruha.co.uk"], "usr-4": ["It was resolved after setting th hostname as below.. sudo /opt/bitnami/apps/wordpress/bnconfig --machine_hostname swagruha.co.uk"]}, "Question": "HI, I am very new to AWS and web-platforms. I managed to create the following AWS website.. After doing some reading.. I am pretty much stuck with one issue and hoping to get some help/advise from the experts.. My domain name: swagruha.co.uk. When try to access that domain, it resolves to actual public domain name of the physical EC2 machine - http://ec2-52-56-161-49.eu-west-2.compute.amazonaws.com/ . I am not sure if that's due to WordPress settings of this website Or if have done wrong setup within route 53. Below I have given the settings of 'A' and 'CANME' value types under route 53. swagruha.co.uk. - A - 52.56.161.49 www.swagruha.co.uk. - CNAME - swagruha.co.uk Please advise.. Thanks BSK", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250555&tstart=50"},
{"Answers": {"usr-1": ["Instance: i-0502f7a14e74ec94a VPC: vpc-056e1b62 I am trying to implement https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario1.html#VPC_Scenario1_Implementation All my security groups, acls, and route tables are open, at this point I am unsure as to what the issue can be. I can connect with the primary elastic IP associated to the primary private IP, but cannot connect to the other Elastic IP. Route table is set to send to an internet gateway. Would appreciate any help to be able to connect to any elastic IPs I create and associate with instance. EDIT: Solved, I needed to add the private IP adresses to my network interface through ssh within the actual instance. Edited by: cold on Mar 3, 2017 6:40 PM Edited by: cold on Mar 4, 2017 12:49 AM"]}, "Question": "Instance: i-0502f7a14e74ec94a VPC: vpc-056e1b62 I am trying to implement https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario1.html#VPC_Scenario1_Implementation All my security groups, acls, and route tables are open, at this point I am unsure as to what the issue can be. I can connect with the primary elastic IP associated to the primary private IP, but cannot connect to the other Elastic IP. Route table is set to send to an internet gateway. Would appreciate any help to be able to connect to any elastic IPs I create and associate with instance. EDIT: Solved, I needed to add the private IP adresses to my network interface through ssh within the actual instance. Edited by: cold on Mar 3, 2017 6:40 PM Edited by: cold on Mar 4, 2017 12:49 AM", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250671&tstart=50"},
{"Answers": {"usr-1": ["Hi, I have a 3-year reserved instance for an m1.large machine. I only need to run my software during Mon-Fri, so I'm wondering if I can save 2/7 of my bill if I stop my instance for 2 days (Sat/Sun) out of 7 days. I'm thinking that with an RI, I've already paid for 24x7x3years of computing time, so my bill will not change regardless of whether I run my instance 5 days or 7 days each week. Is that right? Thank you."], "usr-2": ["You are correct. RI's are paid for in advance, and you do not receive any credit for when they are shut down."], "usr-3": ["Thank you for taking the time to help me. I appreciate it."]}, "Question": "Hi, I have a 3-year reserved instance for an m1.large machine. I only need to run my software during Mon-Fri, so I'm wondering if I can save 2/7 of my bill if I stop my instance for 2 days (Sat/Sun) out of 7 days. I'm thinking that with an RI, I've already paid for 24x7x3years of computing time, so my bill will not change regardless of whether I run my instance 5 days or 7 days each week. Is that right? Thank you.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250634&tstart=50"},
{"Answers": {"usr-1": ["My instance was running fine until a few hours ago, when my Windows remote desktop failed to access the server. I eventually found an email that said my EC2 instance was scheduled for retirement March 17, 2017. I wonder if the hardware has failed already or something. I logged in to the EC2 console, which showed the instance as running. Thinking that a stopping and starting action might move the instance to a different machine (and avoid the retirement notice), I tried to stop the instance. It entered the stopping state, where it has been for a half hour or more. After 10 or 15 minutes, I tried stopping it again, got the forced stop dialog, said Yes please force stop it. But nothing happened. Tried the force stop a few times over the next 15 or 20 minutes. No progress. I would rather not lose my whole software setup by trying to terminate, because I run financial trading software on the machine. So I need to have access to it soon, lest my trading account suffers. What can I do to get back up and running again? Thank you. Kevin Instance i-dd4327a7"], "usr-2": ["if you have latest snapshot. i suggest to terminate and launch new instance."], "usr-3": ["Thank you for your idea. But I don't have a snapshot. I didn't even know that snapshots were possible. When/if I get it running again, I guess I'd better take a snapshot. Is a snapshot the same as an AMI? Where are they stored? Would they disappear if I terminated an instance? Thanks"], "usr-4": ["After a few hours, my instance reached the stopped state. I don't know why. Maybe an automated AWS reaper cleaned up the state. While the instance was stopped, I made a snapshot (thanks to the poster who suggested that), and was able to restart the stopped instance. Now I need to go find out how to \"start a new instance with the snapshot\" so that I know the snapshot actually works."], "usr-5": ["Ok, I found the doc on how to make an AMI from a snapshot, and how to launch an instance from a snapshot. I'm back in business now. Thank you. Boy is AWS a complex wonder..."]}, "Question": "My instance was running fine until a few hours ago, when my Windows remote desktop failed to access the server. I eventually found an email that said my EC2 instance was scheduled for retirement March 17, 2017. I wonder if the hardware has failed already or something. I logged in to the EC2 console, which showed the instance as running. Thinking that a stopping and starting action might move the instance to a different machine (and avoid the retirement notice), I tried to stop the instance. It entered the stopping state, where it has been for a half hour or more. After 10 or 15 minutes, I tried stopping it again, got the forced stop dialog, said Yes please force stop it. But nothing happened. Tried the force stop a few times over the next 15 or 20 minutes. No progress. I would rather not lose my whole software setup by trying to terminate, because I run financial trading software on the machine. So I need to have access to it soon, lest my trading account suffers. What can I do to get back up and running again? Thank you. Kevin Instance i-dd4327a7", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250539&tstart=50"},
{"Answers": {"usr-1": ["I choose Actions > Instance State > Terminate Current instance gets terminated but a new one appears for unknown reason. How to delete this thing completely in a way it never reappears again?"], "usr-2": ["Hi, When an instance has been terminated it takes a while for it to disappear on the console. A new instance should not be automatically launched unless another service, like Autoscaling, launches it . I see you have an Autoscaling Group in place which might be automatically launching new instance when terminate one. Could you provide and instance ID that you terminated for us to confirm if its the Autoscaling group doing this. Regards, Souza S"], "usr-3": ["I have deleted the Autoscaling Group, seems like it helped. Thanks."]}, "Question": "I choose Actions > Instance State > Terminate Current instance gets terminated but a new one appears for unknown reason. How to delete this thing completely in a way it never reappears again?", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250683&tstart=50"},
{"Answers": {"usr-1": ["My volume (vol-766f54f8) is attached to a live EC2 instance (i-320cd7ca) in N. Virginia. It is a Windows 2012 OS on a m3.large type with a software service integrated from an AMI. According to the recent announcement I should be able to expand the volume while attached and in-use. In the console the \"modify\" option is disabled. It is being mounted as xvdb (not the OS drive). It appears the live volume modification feature is not correctly available for me. Please advise."], "usr-2": ["You will probably need to detach your volume, modify it, and then re-attach it. See http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/considerations.html"], "usr-3": ["Hello, Thanks for your post. vol-766f54f8 appears to be of previous generation magnetic type volume. As per our documentation: The previous generation Magnetic volume type is not supported by the volume modification methods described in this topic. However, you can take a snapshot of a Magnetic volume and restore it to a differently configured EBS volume.[1][2] Regards, Artem [1]http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/considerations.html [2]http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-restoring-volume.html"]}, "Question": "My volume (vol-766f54f8) is attached to a live EC2 instance (i-320cd7ca) in N. Virginia. It is a Windows 2012 OS on a m3.large type with a software service integrated from an AMI. According to the recent announcement I should be able to expand the volume while attached and in-use. In the console the 'modify' option is disabled. It is being mounted as xvdb (not the OS drive). It appears the live volume modification feature is not correctly available for me. Please advise.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250655&tstart=50"},
{"Answers": {"usr-1": ["The value \"host\" does not work with --instance-tenancy host Command: $ aws ec2 describe-reserved-instances-offerings --instance-tenancy host Output: An error occurred (InvalidParameterValue) when calling the DescribeReservedInstancesOfferings operation: Value (host) for parameter instanceTenancy is invalid."], "usr-2": ["Hi, Thank you for bringing this to our attention. I understand the DescribeReservedInstancesOfferings [1] lists host, default, dedicated as valid parameters when in fact the only valid parameters are either default or dedicated. We have made our internal team aware of the discrepancy and the public documents will be updated shortly. I apologize for the inconvenience it may have caused. References: 1.http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeReservedInstancesOfferings.html"]}, "Question": "The value 'host' does not work with --instance-tenancy host Command: $ aws ec2 describe-reserved-instances-offerings --instance-tenancy host Output: An error occurred (InvalidParameterValue) when calling the DescribeReservedInstancesOfferings operation: Value (host) for parameter instanceTenancy is invalid.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250711&tstart=50"},
{"Answers": {"usr-1": ["I am trying to import an vm in aws but the import task is stuck at 53% from last 12 hours and it's not moving . TaskType IMPORTINSTANCE TaskId import-i-ffp7zyk6 StatusMessage Progress: 53% DISKIMAGE DiskImageFormat VMDK DiskImageSize 10337810944 AvailabilityZone ap-southeast-1a How to Resolve the Issue?"], "usr-2": ["Hello, I have emailed you details for the VM import task that got stuck, please check your Inbox. Regards Darryn H"]}, "Question": "I am trying to import an vm in aws but the import task is stuck at 53\\% from last 12 hours and it's not moving . TaskType IMPORTINSTANCE TaskId import-i-ffp7zyk6 StatusMessage Progress: 53\\% DISKIMAGE DiskImageFormat VMDK DiskImageSize 10337810944 AvailabilityZone ap-southeast-1a How to Resolve the Issue?", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250719&tstart=50"},
{"Answers": {"usr-1": ["Hello, I have an ec2 instance (ID: i-eb126ea3) that is unreachable since 2 hours ago. I tried stopping it and I also tried making a \"Forced Stop\" several times, but it doesn't stop. It is stuck in the \"stopping\" state. I have also noticed that the EBS volume attached to this instance is in \"attaching\" state. The message error is: \"Volume stuck in attaching since 214 days, 5 hours and 59 minutes ago ago.\". It's weird because the instance has been working correctly last months. Please, any suggestions? Thanks in advance."], "usr-2": ["And suddenly, 2 hours and a half later, the instance stopped and the error in the volume disappeared. Now everything is working fine."]}, "Question": "Hello, I have an ec2 instance (ID: i-eb126ea3) that is unreachable since 2 hours ago. I tried stopping it and I also tried making a 'Forced Stop' several times, but it doesn't stop. It is stuck in the 'stopping' state. I have also noticed that the EBS volume attached to this instance is in 'attaching' state. The message error is: 'Volume stuck in attaching since 214 days, 5 hours and 59 minutes ago ago.'. It's weird because the instance has been working correctly last months. Please, any suggestions? Thanks in advance.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250874&tstart=50"},
{"Answers": {"usr-1": ["Hi Amazon Support Team, I have a volume (vol-ad10bac4) that \"Attachment information\" is blank, but \"State\" is \"in-use\". I tried to \"Force detach volume\", but it didn't work: Error detaching volume vol-ad10bac4: Volume 'vol-ad10bac4'is in the 'available' state. The above error message says that is 'available', but it is not as the \"State\" is \"in-use. There are many similar issue reported and seems that to solve it it is needed Amazon Support intervention, so please put this volume in the 'available' state so I can delete it. Best regards, Alexandre Carneiro"], "usr-2": ["Good day Alexandre I am reaching out to our EBS Support Operations Team to investigate. We will revert back. Regards Imthian R"], "usr-3": ["Our Operations Team confirmed there was an issue on our end, but it has been resolved. The volume is available now. Regards Imthian R"], "usr-4": ["Hi Imthian, Now the volume is available and I was able to delete it, thank you for your help. Best regards, Alexandre V. Carneiro"]}, "Question": "Hi Amazon Support Team, I have a volume (vol-ad10bac4) that 'Attachment information' is blank, but 'State' is 'in-use'. I tried to 'Force detach volume', but it didn't work: Error detaching volume vol-ad10bac4: Volume 'vol-ad10bac4'is in the 'available' state. The above error message says that is 'available', but it is not as the 'State' is 'in-use. There are many similar issue reported and seems that to solve it it is needed Amazon Support intervention, so please put this volume in the 'available' state so I can delete it. Best regards, Alexandre Carneiro", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=250730&tstart=50"},
{"Answers": {"usr-1": ["Hi , I lanch a f1.2xlarge instance, as the log below. the associate stage is passed. and the slot 0 is empty. When I issue the command\"sudo fpga-load-local-image -S 0 -I agfi-0280428d588ea684d\", about 10 seconds later, an error \" Error: operation timed out\" show up. Can anyone help me on this issue? Any suggestions? Thanks in advance. ------------------------------Error message-------------------------------------------------------------- centos@ip-172-31-55-231 aws-fpga$ aws ec2 associate-fpga-image --fpga-image-id afi-050692f8b83ea08b2 --image-id ami-4673d550 { \"Result\": true } centos@ip-172-31-55-231 aws-fpga$ sudo fpga-describe-local-image -S 0 -H Type FpgaImageSlot FpgaImageId StatusName StatusCode ShVersion AFI 0 none cleared 1 0x11241611 Type FpgaImageSlot VendorId DeviceId DBDF AFIDEVICE 0 0x1d0f 0x1042 0000:00:1e.0 centos@ip-172-31-55-231 aws-fpga$ sudo fpga-load-local-image -S 0 -I agfi-0280428d588ea684d Error: operation timed out --Anders"], "usr-2": ["I keep trying on other f1 instances, and got the different error as below centos@ip-172-31-53-196 ~$ aws ec2 associate-fpga-image --fpga-image-id afi-050692f8b83ea08b2 --image-id ami-4673d550 { \"Result\": true } centos@ip-172-31-53-196 ~$ sudo fpga-describe-local-image -S 0 -H Type FpgaImageSlot FpgaImageId StatusName StatusCode ShVersion AFI 0 none cleared 1 0x11241611 Type FpgaImageSlot VendorId DeviceId DBDF AFIDEVICE 0 0x1d0f 0x1042 0000:00:1e.0 centos@ip-172-31-53-196 ~$ sudo fpga-load-local-image -S 0 -I agfi-0280428d588ea684d Error: operation timed out centos@ip-172-31-53-196 ~$ sudo fpga-load-local-image -S 0 -I agfi-0280428d588ea684d Error: operation timed out centos@ip-172-31-53-196 ~$ sudo fpga-load-local-image -S 0 -I agfi-0280428d588ea684d AFI 0 internal-error 4 centos@ip-172-31-53-196 ~$ sudo fpga-load-local-image -S 0 -I agfi-0280428d588ea684d Error: operation timed out centos@ip-172-31-53-196 ~$ sudo fpga-load-local-image -S 0 -I agfi-0280428d588ea684d Error: operation timed out centos@ip-172-31-53-196 ~$ sudo fpga-load-local-image -S 0 -I agfi-0280428d588ea684d AFI 0 internal-error 2 centos@ip-172-31-53-196 ~$ sudo fpga-load-local-image -S 0 -I agfi-0280428d588ea684d AFI 0 busy 3 centos@ip-172-31-53-196 ~$ sudo fpga-load-local-image -S 0 -I agfi-0280428d588ea684d Error: operation timed out"]}, "Question": "Hi , I lanch a f1.2xlarge instance, as the log below. the associate stage is passed. and the slot 0 is empty. When I issue the command'sudo fpga-load-local-image -S 0 -I agfi-0280428d588ea684d', about 10 seconds later, an error ' Error: operation timed out' show up. Can anyone help me on this issue? Any suggestions? Thanks in advance. ------------------------------Error message-------------------------------------------------------------- centos@ip-172-31-55-231 aws-fpga $ aws ec2 associate-fpga-image --fpga-image-id afi-050692f8b83ea08b2 --image-id ami-4673d550 { 'Result': true } centos@ip-172-31-55-231 aws-fpga $ sudo fpga-describe-local-image -S 0 -H Type FpgaImageSlot FpgaImageId StatusName StatusCode ShVersion AFI 0 none cleared 1 0x11241611 Type FpgaImageSlot VendorId DeviceId DBDF AFIDEVICE 0 0x1d0f 0x1042 0000:00:1e.0 centos@ip-172-31-55-231 aws-fpga $ sudo fpga-load-local-image -S 0 -I agfi-0280428d588ea684d Error: operation timed out --Anders", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251018&tstart=25"},
{"Answers": {"usr-1": ["Please kill instance 0fd17f110e2615dc4 I have tried multiple times without success."], "usr-2": ["Hi HSW, The described instance has been terminated, please let me know if you are still experiencing issues."], "usr-3": ["thank you"]}, "Question": "Please kill instance 0fd17f110e2615dc4 I have tried multiple times without success.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251007&tstart=25"},
{"Answers": {"usr-1": ["Is it possible to increase connection timeout on ALB, we have along polling call and it's timing out ."], "usr-2": ["Hi rm3422, Please review the below reference on connection idle timeout. http://docs.aws.amazon.com/elasticloadbalancing/latest/application/application-load-balancers.html#connection-idle-timeout"]}, "Question": "Is it possible to increase connection timeout on ALB, we have along polling call and it's timing out .", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251009&tstart=25"},
{"Answers": {"usr-1": ["Hello, I was troubleshooting a persistent connection issue to port 5000 and I accidentally set Windows firewall to block all incoming connections for public networks: Immediately got locked out of rdp of course. Is it possible someone from amazon approaches it from a private or domain network and changes that? EC2 = i-015cb0ed483e4605d in eu-central-1b Apologies but thanks a lot Arjan Edited by: Arjan on Mar 8, 2017 4:35 PM"], "usr-2": ["Hi Arjan, We do not have access to customer instances. To remedy this issue see \"Remote Desktop Service Issue\" on the below reference : http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/screenshot-service.html"], "usr-3": ["This worked like a CHARM! thanks!"]}, "Question": "Hello, I was troubleshooting a persistent connection issue to port 5000 and I accidentally set Windows firewall to block all incoming connections for public networks: Immediately got locked out of rdp of course. Is it possible someone from amazon approaches it from a private or domain network and changes that? EC2 = i-015cb0ed483e4605d in eu-central-1b Apologies but thanks a lot Arjan Edited by: Arjan on Mar 8, 2017 4:35 PM", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251008&tstart=25"},
{"Answers": {"usr-1": ["Hi, We have an EC2 instance (i-c371984f) running AWS Linux that has suddenly stopped allowing us to SSH to it. We could previously and nothing has changed (from multiple computers here). The error we get is: Using username \"ec2-user\". Server refused our key How can I resolve this? Thanks. We have tried a reboot."], "usr-2": ["working now"]}, "Question": "Hi, We have an EC2 instance (i-c371984f) running AWS Linux that has suddenly stopped allowing us to SSH to it. We could previously and nothing has changed (from multiple computers here). The error we get is: Using username 'ec2-user'. Server refused our key How can I resolve this? Thanks. We have tried a reboot.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251083&tstart=25"},
{"Answers": {"usr-1": ["Hello, I have been trying to set up email in Bitnami Redmine in AWS, and I am getting the following error whenever I try to send a test email: An error occurred while sending mail (getaddrinfo: Name or service not known) Below is my configuration: default: email_delivery: delivery_method: :smtp smtp_settings: address: \"company's address as specified in outlook settings\" port: 25 I have tried the exact same configuration using the Bitnami Redmine Stack accessed from localhost, and it works fine, but after launching Redmine in AWS, the configuration no longer works. I have tried using \"production\" instead of \"default\" and I still get the same error. I have also tried pinging the company address and using the IP address instead and I still get an error. It works in localhost, but not in AWS. I think the issue could be VPN related, because Localhost only works when I am connected to VPN. Is there any way around this for AWS? Thank you. Edited by: User392017 on Mar 10, 2017 8:45 AM"], "usr-2": ["I contacted my IT administrator, and found out that our mail server is not reachable from the internet. I will just use Gmail's SMTP server on port 587 for now, and I may consider something like Amazon SES in the future. It works using Gmail's server."]}, "Question": "Hello, I have been trying to set up email in Bitnami Redmine in AWS, and I am getting the following error whenever I try to send a test email: An error occurred while sending mail (getaddrinfo: Name or service not known) Below is my configuration: default: email_delivery: delivery_method: :smtp smtp_settings: address: 'company's address as specified in outlook settings' port: 25 I have tried the exact same configuration using the Bitnami Redmine Stack accessed from localhost, and it works fine, but after launching Redmine in AWS, the configuration no longer works. I have tried using 'production' instead of 'default' and I still get the same error. I have also tried pinging the company address and using the IP address instead and I still get an error. It works in localhost, but not in AWS. I think the issue could be VPN related, because Localhost only works when I am connected to VPN. Is there any way around this for AWS? Thank you. Edited by: User392017 on Mar 10, 2017 8:45 AM", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251059&tstart=25"},
{"Answers": {"usr-1": ["It looks to me that the Security Group isn't working on one of my servers. My understanding is that the Security group is like a firewall, only inbound rules that I specify should be allowed. I have allowed ports 443 and 22 only. However when I nmap the machine from another computer, it shows 80 as open and I can telnet to the port."], "usr-2": ["Looks like my ISP is doing some strangeness. port scanners on the internet all concur that AWS firewall is working correctly."]}, "Question": "It looks to me that the Security Group isn't working on one of my servers. My understanding is that the Security group is like a firewall, only inbound rules that I specify should be allowed. I have allowed ports 443 and 22 only. However when I nmap the machine from another computer, it shows 80 as open and I can telnet to the port.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251134&tstart=25"},
{"Answers": {"usr-1": ["Hi, i met two problem about ec2 instances. One is instance i-16e70088. it be stop suddenly about 16:00 yesterday (UTC + 8) without any shutdown or reboot command. What's happened yesterday? Another problem is that instance i-00d10a2ffcd356e92 shows \"Retiring: This instance is scheduled for retirement after March 21, 2017 at 5:00:00 AM UTC+8\". I don't want that it be stop or terminated. Why it automatically be set retire at certain time. How to I cancel the retirement setting?"], "usr-2": ["Hello, Thanks for your post. An instance is scheduled to be retired when AWS detects irreparable failure of the underlying hardware hosting the instance. i-00d10a2ffcd356e92 root device is EBS volume, so instance will be stopped and not terminated. The retirement cannot be canceled or postponed. However, you can always stop and start the instance scheduled for retirement yourself before the retirement date. This will make it migrate to another healthy physical host and the event will not affect you. For more information and options that are available to you in cases where an instance is scheduled for retirement, please see: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-retirement.html i-16e70088 was stopped due to a scheduled retirement event. You should have received an email from us on Wednesday, February 22, 2017 informing you of this event. Please check your inbox and spam folder in case email ended up there. Regards, Artem"], "usr-3": ["Thank you, but i don't find the mail, could you tell me the sender's mail address?"]}, "Question": "Hi, i met two problem about ec2 instances. One is instance i-16e70088. it be stop suddenly about 16:00 yesterday (UTC + 8) without any shutdown or reboot command. What's happened yesterday? Another problem is that instance i-00d10a2ffcd356e92 shows 'Retiring: This instance is scheduled for retirement after March 21, 2017 at 5:00:00 AM UTC+8'. I don't want that it be stop or terminated. Why it automatically be set retire at certain time. How to I cancel the retirement setting?", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251143&tstart=25"},
{"Answers": {"usr-1": ["$ sudo yum install php-pear php56-fpm The above commands will fail as yum will prioritise php-pear dependencies and attempt to install php 5.5 packages. This will conflict with php56-fpm packages and its dependencies. The command will fail. This combination should and previously worked (we install it using configuration management) so something has changed recently? Is this fixable within the Amazon repository? Find below shell output Loaded plugins: priorities, update-motd, upgrade-helper amzn-main/latest | 2.1 kB 00:00 amzn-updates/latest | 2.3 kB 00:00 Resolving Dependencies --> Running transaction check ---> Package php-pear.noarch 1:1.10.1-1.19.amzn1 will be installed --> Processing Dependency: php-bz2 for package: 1:php-pear-1.10.1-1.19.amzn1.noarch --> Processing Dependency: php-xml for package: 1:php-pear-1.10.1-1.19.amzn1.noarch --> Processing Dependency: php-cli for package: 1:php-pear-1.10.1-1.19.amzn1.noarch --> Processing Dependency: php-zlib for package: 1:php-pear-1.10.1-1.19.amzn1.noarch --> Processing Dependency: php-common for package: 1:php-pear-1.10.1-1.19.amzn1.noarch --> Processing Dependency: php-tokenizer for package: 1:php-pear-1.10.1-1.19.amzn1.noarch --> Processing Dependency: php-pcre for package: 1:php-pear-1.10.1-1.19.amzn1.noarch --> Processing Dependency: php-ftp for package: 1:php-pear-1.10.1-1.19.amzn1.noarch --> Processing Dependency: php-posix for package: 1:php-pear-1.10.1-1.19.amzn1.noarch ---> Package php56-fpm.x86_64 0:5.6.29-1.131.amzn1 will be installed --> Processing Dependency: php56-common(x86-64) = 5.6.29-1.131.amzn1 for package: php56-fpm-5.6.29-1.131.amzn1.x86_64 --> Processing Dependency: php-common(x86-64) = 5.6.29-1.131.amzn1 for package: php56-fpm-5.6.29-1.131.amzn1.x86_64 --> Processing Dependency: php56-common for package: php56-fpm-5.6.29-1.131.amzn1.x86_64 --> Running transaction check ---> Package php-cli.x86_64 0:5.3.29-1.8.amzn1 will be installed --> Processing Dependency: libgmp.so.3()(64bit) for package: php-cli-5.3.29-1.8.amzn1.x86_64 ---> Package php-common.x86_64 0:5.3.29-1.8.amzn1 will be installed ---> Package php-process.x86_64 0:5.3.29-1.8.amzn1 will be installed ---> Package php-xml.x86_64 0:5.3.29-1.8.amzn1 will be installed ---> Package php56-common.x86_64 0:5.6.29-1.131.amzn1 will be installed --> Processing Dependency: php56-process(x86-64) = 5.6.29-1.131.amzn1 for package: php56-common-5.6.29-1.131.amzn1.x86_64 --> Processing Dependency: php56-xml(x86-64) = 5.6.29-1.131.amzn1 for package: php56-common-5.6.29-1.131.amzn1.x86_64 --> Processing Dependency: php56-cli(x86-64) = 5.6.29-1.131.amzn1 for package: php56-common-5.6.29-1.131.amzn1.x86_64 --> Processing Dependency: php56-jsonc(x86-64) for package: php56-common-5.6.29-1.131.amzn1.x86_64 --> Running transaction check ---> Package compat-gmp4.x86_64 0:4.3.2-1.14.amzn1 will be installed ---> Package php56-cli.x86_64 0:5.6.29-1.131.amzn1 will be installed ---> Package php56-jsonc.x86_64 0:1.3.6-1.19.amzn1 will be installed ---> Package php56-process.x86_64 0:5.6.29-1.131.amzn1 will be installed ---> Package php56-xml.x86_64 0:5.6.29-1.131.amzn1 will be installed --> Processing Conflict: php56-process-5.6.29-1.131.amzn1.x86_64 conflicts php-process < 5.5.22-1.98 --> Processing Conflict: php56-xml-5.6.29-1.131.amzn1.x86_64 conflicts php-xml < 5.5.22-1.98 --> Processing Conflict: php56-common-5.6.29-1.131.amzn1.x86_64 conflicts php-common < 5.5.22-1.98 --> Processing Conflict: php56-cli-5.6.29-1.131.amzn1.x86_64 conflicts php-cli < 5.5.22-1.98 --> Finished Dependency Resolution Error: php56-cli conflicts with php-cli-5.3.29-1.8.amzn1.x86_64 Error: php56-common conflicts with php-common-5.3.29-1.8.amzn1.x86_64 Error: php56-xml conflicts with php-xml-5.3.29-1.8.amzn1.x86_64 Error: php56-process conflicts with php-process-5.3.29-1.8.amzn1.x86_64 You could try using --skip-broken to work around the problem You could try running: rpm -Va --nofiles --nodigest"], "usr-2": ["Hello, php-pear has many optional dependency sets, (php, php54, php55, php56). If one of these versions is installed first, it will accept those for dependencies. If no php is installed first, it will pick php-* packages. Doing these in a single yum transaction leads to it picking two versions at the same time. Doing the install in 2 steps works. $ sudo yum install php56-fpm $ sudo yum install php-pear Regards, Arun T."]}, "Question": "$ sudo yum install php-pear php56-fpm The above commands will fail as yum will prioritise php-pear dependencies and attempt to install php 5.5 packages. This will conflict with php56-fpm packages and its dependencies. The command will fail. This combination should and previously worked (we install it using configuration management) so something has changed recently? Is this fixable within the Amazon repository? Find below shell output Loaded plugins: priorities, update-motd, upgrade-helper amzn-main/latest | 2.1 kB 00:00 amzn-updates/latest | 2.3 kB 00:00 Resolving Dependencies --> Running transaction check ---> Package php-pear.noarch 1:1.10.1-1.19.amzn1 will be installed --> Processing Dependency: php-bz2 for package: 1:php-pear-1.10.1-1.19.amzn1.noarch --> Processing Dependency: php-xml for package: 1:php-pear-1.10.1-1.19.amzn1.noarch --> Processing Dependency: php-cli for package: 1:php-pear-1.10.1-1.19.amzn1.noarch --> Processing Dependency: php-zlib for package: 1:php-pear-1.10.1-1.19.amzn1.noarch --> Processing Dependency: php-common for package: 1:php-pear-1.10.1-1.19.amzn1.noarch --> Processing Dependency: php-tokenizer for package: 1:php-pear-1.10.1-1.19.amzn1.noarch --> Processing Dependency: php-pcre for package: 1:php-pear-1.10.1-1.19.amzn1.noarch --> Processing Dependency: php-ftp for package: 1:php-pear-1.10.1-1.19.amzn1.noarch --> Processing Dependency: php-posix for package: 1:php-pear-1.10.1-1.19.amzn1.noarch ---> Package php56-fpm.x86_64 0:5.6.29-1.131.amzn1 will be installed --> Processing Dependency: php56-common(x86-64) = 5.6.29-1.131.amzn1 for package: php56-fpm-5.6.29-1.131.amzn1.x86_64 --> Processing Dependency: php-common(x86-64) = 5.6.29-1.131.amzn1 for package: php56-fpm-5.6.29-1.131.amzn1.x86_64 --> Processing Dependency: php56-common for package: php56-fpm-5.6.29-1.131.amzn1.x86_64 --> Running transaction check ---> Package php-cli.x86_64 0:5.3.29-1.8.amzn1 will be installed --> Processing Dependency: libgmp.so.3()(64bit) for package: php-cli-5.3.29-1.8.amzn1.x86_64 ---> Package php-common.x86_64 0:5.3.29-1.8.amzn1 will be installed ---> Package php-process.x86_64 0:5.3.29-1.8.amzn1 will be installed ---> Package php-xml.x86_64 0:5.3.29-1.8.amzn1 will be installed ---> Package php56-common.x86_64 0:5.6.29-1.131.amzn1 will be installed --> Processing Dependency: php56-process(x86-64) = 5.6.29-1.131.amzn1 for package: php56-common-5.6.29-1.131.amzn1.x86_64 --> Processing Dependency: php56-xml(x86-64) = 5.6.29-1.131.amzn1 for package: php56-common-5.6.29-1.131.amzn1.x86_64 --> Processing Dependency: php56-cli(x86-64) = 5.6.29-1.131.amzn1 for package: php56-common-5.6.29-1.131.amzn1.x86_64 --> Processing Dependency: php56-jsonc(x86-64) for package: php56-common-5.6.29-1.131.amzn1.x86_64 --> Running transaction check ---> Package compat-gmp4.x86_64 0:4.3.2-1.14.amzn1 will be installed ---> Package php56-cli.x86_64 0:5.6.29-1.131.amzn1 will be installed ---> Package php56-jsonc.x86_64 0:1.3.6-1.19.amzn1 will be installed ---> Package php56-process.x86_64 0:5.6.29-1.131.amzn1 will be installed ---> Package php56-xml.x86_64 0:5.6.29-1.131.amzn1 will be installed --> Processing Conflict: php56-process-5.6.29-1.131.amzn1.x86_64 conflicts php-process < 5.5.22-1.98 --> Processing Conflict: php56-xml-5.6.29-1.131.amzn1.x86_64 conflicts php-xml < 5.5.22-1.98 --> Processing Conflict: php56-common-5.6.29-1.131.amzn1.x86_64 conflicts php-common < 5.5.22-1.98 --> Processing Conflict: php56-cli-5.6.29-1.131.amzn1.x86_64 conflicts php-cli < 5.5.22-1.98 --> Finished Dependency Resolution Error: php56-cli conflicts with php-cli-5.3.29-1.8.amzn1.x86_64 Error: php56-common conflicts with php-common-5.3.29-1.8.amzn1.x86_64 Error: php56-xml conflicts with php-xml-5.3.29-1.8.amzn1.x86_64 Error: php56-process conflicts with php-process-5.3.29-1.8.amzn1.x86_64 You could try using --skip-broken to work around the problem You could try running: rpm -Va --nofiles --nodigest", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251167&tstart=25"},
{"Answers": {"usr-1": ["We recently noticed that our ALBs have started adding the ALB's port to the HTTP_HOST header. That is, instead of something like 'foo.tiiscoringengine.com' we'd get 'foo.tiiscoringengine.com:8000' where '8000' is the port the ALB is listening on. Is this intended behavior or a bug? (I'm leaning toward the latter because it appears this happened four years ago with ELBs: https://forums.aws.amazon.com/thread.jspa?messageID=424938%F1%A7%AF%AA) Thanks!"], "usr-2": ["Hi, The behavior that you're seeing is intended: It has to be shown since 8000 is a non-standard port. Regards, Arun T."], "usr-3": ["Interesting! It's worth noting that this just changed recently. Do you think it's possible to add something about this to the documentation? We've worked around it in our application servers and I suspect others will need to do the same. Thank you!"]}, "Question": "We recently noticed that our ALBs have started adding the ALB's port to the HTTP_HOST header. That is, instead of something like 'foo.tiiscoringengine.com' we'd get 'foo.tiiscoringengine.com:8000' where '8000' is the port the ALB is listening on. Is this intended behavior or a bug? (I'm leaning toward the latter because it appears this happened four years ago with ELBs: https://forums.aws.amazon.com/thread.jspa?messageID=424938\\%F1\\%A7\\%AF\\%AA ) Thanks!", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251155&tstart=25"},
{"Answers": {"usr-1": ["Hello, in order to release EIP ???.???.???.??? could you remove reverse DNS and un lock that IP address? Thanks in advance. Best regards. Edited by: JerryC@AWS on Mar 12, 2017 7:49 PM Remove EIP address."], "usr-2": ["Hello, For your security, I have removed your EIP from your post. I have reset rDNS for your IP. Could you please try to release the IP? I hope this help."]}, "Question": "Hello, in order to release EIP ???.???.???.??? could you remove reverse DNS and un lock that IP address? Thanks in advance. Best regards. Edited by: JerryC@AWS on Mar 12, 2017 7:49 PM Remove EIP address.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251291&tstart=25"},
{"Answers": {"usr-1": ["We were making use of 54.228.186.102 but it must have been disassociated - is there any way we can get this re-allocated to our account? This wouldn't normally be an issue but it has been in use specifically for customers of ours that can only create firewall rules based on IP addresses."], "usr-2": ["Unfortunately once you release an EIP it is taken back into our IP pool for use by other customers. Regards, Darryn H"]}, "Question": "We were making use of 54.228.186.102 but it must have been disassociated - is there any way we can get this re-allocated to our account? This wouldn't normally be an issue but it has been in use specifically for customers of ours that can only create firewall rules based on IP addresses.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251352&tstart=25"},
{"Answers": {"usr-1": ["After apache is configured and tested by the ip address. Boot it and check it again and left running , when I return by mar 13 I found the instance shutdown and when restarted audit service, apache, kdump found failed.. for apache reinstated the new IP address but it doesn't work again ?? Help, clue"], "usr-2": ["Hello, Thank you for contacting us. In order to troubleshoot this issue, could you please provide us with the instance id so that we can have a look? Best regards, Karan S."], "usr-3": ["id i-00ed513f07d2a860 if I miss something pls inform me. Thank you. Edited by: Fanta on Mar 13, 2017 7:52 PM"], "usr-4": ["Hello, I'm seeing your public IP address is reachable on port 80 and pulls up the default Apache page. Are you still having issues? I did notice that the IP you're using is not an EIP, so if you wanted a static IP you'd want to associate an EIP to that EC2 instance as described here: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html#working-with-eips Regards, Nick"], "usr-5": ["It was my miss understanding, I should leave the configuration as it is so that it can bind with public address. Now I am proceeding forward........ Thank you,"]}, "Question": "After apache is configured and tested by the ip address. Boot it and check it again and left running , when I return by mar 13 I found the instance shutdown and when restarted audit service, apache, kdump found failed.. for apache reinstated the new IP address but it doesn't work again ?? Help, clue", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251349&tstart=25"},
{"Answers": {"usr-1": ["I have a php function within a php class that runs a select query. The function calls a select statement that runs perfectly on the local machine but throws an internal server 500 error on EC2 when I call the function from the browser. The statements on the local machine and EC2 were identical. I have simplified the statement on the EC2 server to \"Select * FROM t_ddxshort\" but I still get the error when it is executed. I have debugged the function and only get errors when the Select statement is executed. This works: public function gett_ddxicd10specific() { $stmt = mysqli_prepare($this->connection, \"SELECT * FROM t_ddxshort\"); echo('works'); echo('okay'); mysqli_stmt_free_result($stmt); mysqli_close($this->connection); } and returns this: worksokay This does not work: public function gett_ddxicd10specific() { $stmt = mysqli_prepare($this->connection, \"SELECT * FROM t_ddxshort\"); echo('works'); mysqli_stmt_execute($stmt); $this->throwExceptionOnError(); echo('okay'); mysqli_stmt_free_result($stmt); mysqli_close($this->connection); } and returns this 500 Internal Server Error works The local table and the RDS table (t_ddxshort) are identical down to the encoding and collation. Both tables have two columns \"idt_ddxshort\" and \"diagnosis\". I use SequelPro for managing my databases and the query works perfectly in SequelPro for local and RDS. The syntax is correct and simple. All my other classes and functions in my application work fine and all other queries execute without error. The connection for all classes is \"include connection.php\" and is included at the start of the class. I have deleted the file and recreated the file. I have created a file will another name twice. I can't understand why this one query will not work on EC2/RDS. Thanks in advance for your help."], "usr-2": ["When I removed this line $this->throwExceptionOnError(); the statement executed."]}, "Question": "I have a php function within a php class that runs a select query. The function calls a select statement that runs perfectly on the local machine but throws an internal server 500 error on EC2 when I call the function from the browser. The statements on the local machine and EC2 were identical. I have simplified the statement on the EC2 server to 'Select - FROM t_ddxshort' but I still get the error when it is executed. I have debugged the function and only get errors when the Select statement is executed. This works: public function gett_ddxicd10specific() { $stmt = mysqli_prepare($this->connection, 'SELECT - FROM t_ddxshort'); echo('works'); echo('okay'); mysqli_stmt_free_result($stmt); mysqli_close($this->connection); } and returns this: worksokay This does not work: public function gett_ddxicd10specific() { $stmt = mysqli_prepare($this->connection, 'SELECT - FROM t_ddxshort'); echo('works'); mysqli_stmt_execute($stmt); $this->throwExceptionOnError(); echo('okay'); mysqli_stmt_free_result($stmt); mysqli_close($this->connection); } and returns this 500 Internal Server Error works The local table and the RDS table (t_ddxshort) are identical down to the encoding and collation. Both tables have two columns 'idt_ddxshort' and 'diagnosis'. I use SequelPro for managing my databases and the query works perfectly in SequelPro for local and RDS. The syntax is correct and simple. All my other classes and functions in my application work fine and all other queries execute without error. The connection for all classes is 'include connection.php' and is included at the start of the class. I have deleted the file and recreated the file. I have created a file will another name twice. I can't understand why this one query will not work on EC2/RDS. Thanks in advance for your help.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251446&tstart=25"},
{"Answers": {"usr-1": ["Hello! I submitted a request to increase g2.2xlarge instance limit. But after 24 hours its status is still unassigned. Can anyone tell me how to increase the limit? Case id: 2116242111"]}, "Question": "Hello! I submitted a request to increase g2.2xlarge instance limit. But after 24 hours its status is still unassigned. Can anyone tell me how to increase the limit? Case id: 2116242111", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251699&tstart=25"},
{"Answers": {"usr-1": ["Hi! I'm switching over from a managed web host to AWS, using EC2+EBS. Everything has gone well so far, except that I can't get my server-side includes working correctly. File is named 'index.shtml' and is being loaded correctly when I navigate to the parent dir in a browser. I've also given that file 'x' permissions, for the XBitHack method. I've edited my httpd.conf file with the following: <Directory \"/var/www/html\"> # # Possible values for the Options directive are \"None\", \"All\", # or any combination of: # Indexes Includes FollowSymLinks SymLinksifOwnerMatch ExecCGI MultiViews # # Note that \"MultiViews\" must be named *explicitly* --- \"Options All\" # doesn't give it to you. # # The Options directive is both complicated and important. Please see # http://httpd.apache.org/docs/2.4/mod/core.html#options # for more information. # Options Includes FollowSymLinks \u00a0 # # AllowOverride controls what directives may be placed in .htaccess files. # It can be \"All\", \"None\", or any combination of the keywords: # Options FileInfo AuthConfig Limit # AllowOverride All \u00a0 # # Controls who can get stuff from this server. # Require all granted \u00a0 AddType text/html .shtml AddOutputFilter INCLUDES .shtml AddHandler server-parsed .shtml \u00a0 XBitHack on </Directory> I've also added the following line to load the 'include' module, but when restarting Apache it warned me that the module was already loaded, so I commented it out. LoadModule include_module modules/mod_include.so In addition, I tried adding an .htaccess file at the same location as the index.shtml, with the following: AddType text/html .shtml AddOutputFilter INCLUDES .shtml \u00a0 Options +Includes \u00a0 XBitHack on And still my server side includes aren't working. The include syntax should be fine, it's working on my old server: <!-- #include file=\"footer2.shtml\" --> If you'd like to see the actual pages, this is the working page on the old server: http://mechanicalvein.com All of the pages (except 'Home') should have a footer section at the bottom with Facebook/Twitter embeds & misc social media info. You can see it **not** working on the new EC2+EBS server here: http://34.205.236.65/mechanicalvein.com I've been scouring the internet for clues and trying every variation I can find, and still haven't been able to get it to work. Been going crazy, if anyone can provide any helpful input it would be massively appreciated."], "usr-2": ["I've been wrestling with this for at least a few days, but I found the problem and fixed it! The include statement has a space between <!-- and #include. I removed that space and it works now! Weird that it was working on the old server with the space in there, and not on the new server. For clarity, for anyone else with the same problem..... Wrong: <!-- #include file=\"footer2.shtml\" --> Right: <!--#include file=\"footer2.shtml\" --> If anyone knows why it may have worked with the extra whitespace on the old server, I'm all ears."]}, "Question": "Hi! I'm switching over from a managed web host to AWS, using EC2+EBS. Everything has gone well so far, except that I can't get my server-side includes working correctly. File is named 'index.shtml' and is being loaded correctly when I navigate to the parent dir in a browser. I've also given that file 'x' permissions, for the XBitHack method. I've edited my httpd.conf file with the following: <Directory '/var/www/html' > # # Possible values for the Options directive are 'None' , 'All' , # or any combination of: # Indexes Includes FollowSymLinks SymLinksifOwnerMatch ExecCGI MultiViews # # Note that 'MultiViews' must be named -explicitly- --- 'Options All' # doesn 't give it to you. # # The Options directive is both complicated and important. Please see # http: //httpd.apache.org/docs/2.4/mod/core.html#options # for more information. # Options Includes FollowSymLinks \u00a0 # # AllowOverride controls what directives may be placed in .htaccess files. # It can be 'All' , 'None' , or any combination of the keywords: # Options FileInfo AuthConfig Limit # AllowOverride All \u00a0 # # Controls who can get stuff from this server. # Require all granted \u00a0 AddType text/html .shtml AddOutputFilter INCLUDES .shtml AddHandler server-parsed .shtml \u00a0 XBitHack on </Directory> I've also added the following line to load the 'include' module, but when restarting Apache it warned me that the module was already loaded, so I commented it out. LoadModule include_module modules/mod_include.so In addition, I tried adding an .htaccess file at the same location as the index.shtml, with the following: AddType text/html .shtml AddOutputFilter INCLUDES .shtml \u00a0 Options +Includes \u00a0 XBitHack on And still my server side includes aren't working. The include syntax should be fine, it's working on my old server: <!-- #include file= 'footer2.shtml' --> If you'd like to see the actual pages, this is the working page on the old server: http://mechanicalvein.com All of the pages (except 'Home') should have a footer section at the bottom with Facebook/Twitter embeds and misc social media info. You can see it --not-- working on the new EC2+EBS server here: http://34.205.236.65/mechanicalvein.com I've been scouring the internet for clues and trying every variation I can find, and still haven't been able to get it to work. Been going crazy, if anyone can provide any helpful input it would be massively appreciated.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251735&tstart=25"},
{"Answers": {"usr-1": ["Greetings, I was fiddling around with my VPC this weekend and now I am not able to connect to anything outside the VPC with programs like ftp client and curl. I think I put things back to where they were on Friday but I'm not sure. Is there any way someone can look at my setup? Any help greatly appreciated!! Craig"], "usr-2": ["If it helps my instance is i-06a31f56f327d396e Please help! I don't know what I changed to screw this up."], "usr-3": ["I figured it out. I had a mistake in my route table."]}, "Question": "Greetings, I was fiddling around with my VPC this weekend and now I am not able to connect to anything outside the VPC with programs like ftp client and curl. I think I put things back to where they were on Friday but I'm not sure. Is there any way someone can look at my setup? Any help greatly appreciated!! Craig", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251767&tstart=25"},
{"Answers": {"usr-1": ["Hi, I need to increase the limit of the number of running On-demand instance in region Virginia and Ireland. When I create a case, I'm unable to select the option to increase the region limit, just the instance type. How to do that? Regards,"]}, "Question": "Hi, I need to increase the limit of the number of running On-demand instance in region Virginia and Ireland. When I create a case, I'm unable to select the option to increase the region limit, just the instance type. How to do that? Regards,", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251834&tstart=25"},
{"Answers": {"usr-1": ["Everytime I launch a new instance or restart an instance with a new ip address, I can ssh into it fine and login as ec2-user. However after a few seconds, the ssh session terminates with a connection timeout error. If I am using the same instance still, I continue to get this error and it only stops if I stop and start the instance again with a new ip address but then the same problem eventually occurs. Can someone look into this issue? The current instance I am working with is i-0a4f5f4e7ab2d58ae. I've looked at other threads and the solution to those was related to the security group attached to the instance. In this case though, I don't think it's the issue because I have set the instance to accept ssh traffic from all sources and I can ssh into it fine initially. I think the issue has to do with my account. I recently reopened my account and I am thinking the issue here is related to that, but I did check my billing information on the dashboard and saw that all invoices were paid. Edited by: lasred on Mar 24, 2017 1:57 PM Edited by: lasred on Mar 24, 2017 2:00 PM"], "usr-2": ["Hello lasred, I have reached out to Customer Support and they confirmed that you have a case open on there for this very issue. One of my colleagues will be in touch with you shortly to sort this out for you. Regards Ash"], "usr-3": ["Thanks Ash! Everything worked out. There was an issue with my account."], "usr-4": ["My Account was just reinstated and I have the same issue (Connection works just once). My instance is i-0f741ee650a15c39f (UBUNTU AMI) which is now not usable. I suspect it is an account issue (since it was reinstated recently). Please help. Thanks rafi2013"]}, "Question": "Everytime I launch a new instance or restart an instance with a new ip address, I can ssh into it fine and login as ec2-user. However after a few seconds, the ssh session terminates with a connection timeout error. If I am using the same instance still, I continue to get this error and it only stops if I stop and start the instance again with a new ip address but then the same problem eventually occurs. Can someone look into this issue? The current instance I am working with is i-0a4f5f4e7ab2d58ae. I've looked at other threads and the solution to those was related to the security group attached to the instance. In this case though, I don't think it's the issue because I have set the instance to accept ssh traffic from all sources and I can ssh into it fine initially. I think the issue has to do with my account. I recently reopened my account and I am thinking the issue here is related to that, but I did check my billing information on the dashboard and saw that all invoices were paid. Edited by: lasred on Mar 24, 2017 1:57 PM Edited by: lasred on Mar 24, 2017 2:00 PM", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252166&tstart=0"},
{"Answers": {"usr-1": ["Is there a problem with EIP at eu-west? Earlier today, I created an instance and couldn't get connected to it at all. I ended up terminating the instance and creating a fresh one. This instance, i-0e1c0158daaa589d0, I managed to get connected to it and was entering a command when connectivity was lost. Now, I'm unable to connect to it. All of my business services, running under a different AWS account and have not had any EIP changes, are all contactable and operational. The instance given above are is still running, if a AWS bod would like to take a look."], "usr-2": ["Good day We had a look at the instance and confirm it has been terminated. I had a look at the history and the underlying host it is residing on. There was no issue on the underlying hardware or anything we can identify from our end. The only thin i identified was the health check failure which is due to an internal issue within the instance. at this time: 2017-03-21 08:33 UTC Regards Imthian R"], "usr-3": ["OK. I have set up a test instance (i-0b8ae5ca7c140a29d). This is a clean instance created from the Ubuntu 16 AMI. It's never been logged into, just created and an EIP attached. The instance doesn't have any security credentials associated with it, so nobody is able to log into it. When the instance started, it was reachable via ping. After a few minutes, it stopped responding to ping. Please can you let me know why is this instance unreachable? Can anyone reading this ping the machine? It's IP address is 34.252.227.100. If you do try, please if you're successful or fail."], "usr-4": ["I'm currently paying for this test instance. Should I continue leave it running? I'd rather not be paying for something you're not able/going to look at."], "usr-5": ["Hello, Please feel free to delete the instance. I will be opening a case to you shortly containing the details of the issue. This case will be associated with the account from which you launched the test instance. Regards, Tim"], "usr-6": ["Thanks for the reply. The account adjustment appears to have corrected the issue."]}, "Question": "Is there a problem with EIP at eu-west? Earlier today, I created an instance and couldn't get connected to it at all. I ended up terminating the instance and creating a fresh one. This instance, i-0e1c0158daaa589d0, I managed to get connected to it and was entering a command when connectivity was lost. Now, I'm unable to connect to it. All of my business services, running under a different AWS account and have not had any EIP changes, are all contactable and operational. The instance given above are is still running, if a AWS bod would like to take a look.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=251814&tstart=25"},
{"Answers": {"usr-1": ["I created a volume from a snapshot and attached it to a new ec2 instance as the root volume (/dev/sda1). The instance shows as running but 1/2 checks passed and instance reachability check failed. The instance that I am trying to attach to is similar in all the ways I can think of to the original instance. The instance ID is i-0c9ce0746fc1f4625. There are no errors or warnings in the system log available through the console. I compared the log to a working log file and noticed that it never gets to the cloud-init but again, don't see any errors. i also tried several other approaches, all with the same problem. Instance i-09bd77f8d47c035ab and i-04678ee0727403b90 were created differently, but show the same status. If I detach the original volume and attach it as a block device to an instance, it works fine. I am only having this issue when trying to attach this volume as root. I've checked things like Kernel ID and RAM Disk ID (based on other posts) but mine are blank because I'm using HVM. Please help me figure out why I can not create a new instance from this volume/snapshot. Thanks! Edited by: phillyeagles on Mar 24, 2017 6:25 PM Edited by: phillyeagles on Mar 27, 2017 9:27 AM"], "usr-2": ["Problem was solved by editing network config to use DHCP instead of static IP addressing. For more information, see here: https://aws.amazon.com/articles/5213606968661598"]}, "Question": "I created a volume from a snapshot and attached it to a new ec2 instance as the root volume (/dev/sda1). The instance shows as running but 1/2 checks passed and instance reachability check failed. The instance that I am trying to attach to is similar in all the ways I can think of to the original instance. The instance ID is i-0c9ce0746fc1f4625. There are no errors or warnings in the system log available through the console. I compared the log to a working log file and noticed that it never gets to the cloud-init but again, don't see any errors. i also tried several other approaches, all with the same problem. Instance i-09bd77f8d47c035ab and i-04678ee0727403b90 were created differently, but show the same status. If I detach the original volume and attach it as a block device to an instance, it works fine. I am only having this issue when trying to attach this volume as root. I've checked things like Kernel ID and RAM Disk ID (based on other posts) but mine are blank because I'm using HVM. Please help me figure out why I can not create a new instance from this volume/snapshot. Thanks! Edited by: phillyeagles on Mar 24, 2017 6:25 PM Edited by: phillyeagles on Mar 27, 2017 9:27 AM", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252221&tstart=0"},
{"Answers": {"usr-1": ["Signed up for AWS today and started building up a setup for AWS Arch training... Instance id is: i-054533e7475e5e8a1 Created new vPC, new subnets, created routing table and associated subnets Created Internet Gateway and attached to vPC Created Security group with SSH inbound and IPv4 ICMP from anywhere (0.0.0.0/0) Created and associated an Elastic IP with the instance But I can neither SSH nor ping the instance. The basic status checks say the instance is reachable and the startup log looks okay. Am I missing something? Thanks - Jim. Edited by: Jim23333 on Mar 25, 2017 4:16 PM"]}, "Question": "Signed up for AWS today and started building up a setup for AWS Arch training... Instance id is: i-054533e7475e5e8a1 Created new vPC, new subnets, created routing table and associated subnets Created Internet Gateway and attached to vPC Created Security group with SSH inbound and IPv4 ICMP from anywhere (0.0.0.0/0) Created and associated an Elastic IP with the instance But I can neither SSH nor ping the instance. The basic status checks say the instance is reachable and the startup log looks okay. Am I missing something? Thanks - Jim. Edited by: Jim23333 on Mar 25, 2017 4:16 PM", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252210&tstart=0"},
{"Answers": {"usr-1": ["not able to SSH, with above error msg. I opened all ports,icmp,ssh, assigned my IP/any IP. nothing worked. I previously suspended my account and re-activated recently. same issue with following thread, https://forums.aws.amazon.com/thread.jspa?threadID=128361 my instance ID: i-02ddb00f87f4b154e I would like to know why it is causing it, will this happened again if I create other instances? Thank you in advance."], "usr-2": ["Hi, I have reached out to the concerned team regarding your issue. As soon we hear back from them we will update you. Thanks, Usamah"], "usr-3": ["Hi, The concerned service team has responded. When the account was re-opened the account was not completely re-instated. It has been now and you should be able to ssh. Let us know if you face any similar problems."]}, "Question": "not able to SSH, with above error msg. I opened all ports,icmp,ssh, assigned my IP/any IP. nothing worked. I previously suspended my account and re-activated recently. same issue with following thread, https://forums.aws.amazon.com/thread.jspa?threadID=128361 my instance ID: i-02ddb00f87f4b154e I would like to know why it is causing it, will this happened again if I create other instances? Thank you in advance.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252302&tstart=0"},
{"Answers": {"usr-1": ["Hi all, after migrating some of our webservers as new EC2 instances to AWS, we now reached the Elastic IP limit. How can we spawn more than 5 webservers, that shall be reachable via internet? The documentation (\"http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html#using-instance-addressing-limit\") says: \"\u2026and to use DNS hostnames for all other inter-node communication.\u2026\" BUT: as the AWS generated DNS-host names are linked to the (sometimes changing) IP, I cannot set a CNAME on them. After reboot, a new IP and DNS entry (foo.bar.compute.amazonaws.com) is assigned and the CNAME will not work any more. So... how to connect more than five public EC2 servers to their domains? Thank you for your help Jens"], "usr-2": ["Hi, If required, you may request to increase your EIP limit in your region. http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Appendix_Limits.html#vpc-limits-eips Regards, Jayakrishnan L"], "usr-3": ["Hi Jayakrishnan L, If required, you may request to increase your EIP limit in your region. thank you for your answer. I hoped, that there was an easy way to get along with only the 5 Elastic IPs. Because of your recommendation we ordered now some more Elastic IPs which will solve this issue for now. Jens"]}, "Question": "Hi all, after migrating some of our webservers as new EC2 instances to AWS, we now reached the Elastic IP limit. How can we spawn more than 5 webservers, that shall be reachable via internet? The documentation ('http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html#using-instance-addressing-limit') says: '\u2026and to use DNS hostnames for all other inter-node communication.\u2026' BUT: as the AWS generated DNS-host names are linked to the (sometimes changing) IP, I cannot set a CNAME on them. After reboot, a new IP and DNS entry (foo.bar.compute.amazonaws.com) is assigned and the CNAME will not work any more. So... how to connect more than five public EC2 servers to their domains? Thank you for your help Jens", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252303&tstart=0"},
{"Answers": {"usr-1": ["On 3/19 I received an email that my instance (i-dcd740d1) was scheduled for retirement on 4/3 due to underlying hardware degradation and that it may already be unreachable. Sure enough, I could not reach it. I read a number of articles on how to approach this and found many stating that if one was able to stop and restart an EBS backed instance (it is) it would be migrated to different hardware and all would be well. I did manage to stop the instance (it required a force stop) and was able to start it again. At that point it was reachable and functioning normally - and still is. So, I thought - great, all is well! However, I see conflicting information. I click on the instance and under the Description tab 'Scheduled Events:\" lists \"no scheduled event\". BUT - at the top of the main console page there is a \"bell\". Clicking on the 'bell' shows \"1 scheduled change\" under Alerts. The scheduled change is \"EC2 persistent instance retirement scheduled\" with a status of \"upcoming\". And the instance is i-dcd740d1. So, I'm hoping someone can shed some light on which to believe. Will the instance disappear April 3, 2017, at 12:00:00 PM UTC-4 as indicated in the scheduled change or is this a leftover message? Thanks in advance for any insight you can provide! jerry"], "usr-2": ["Hello, I have emailed you details for the your instance scheduled for retirement , please check your Inbox. Regards Darryn H"]}, "Question": "On 3/19 I received an email that my instance (i-dcd740d1) was scheduled for retirement on 4/3 due to underlying hardware degradation and that it may already be unreachable. Sure enough, I could not reach it. I read a number of articles on how to approach this and found many stating that if one was able to stop and restart an EBS backed instance (it is) it would be migrated to different hardware and all would be well. I did manage to stop the instance (it required a force stop) and was able to start it again. At that point it was reachable and functioning normally - and still is. So, I thought - great, all is well! However, I see conflicting information. I click on the instance and under the Description tab 'Scheduled Events:' lists 'no scheduled event'. BUT - at the top of the main console page there is a 'bell'. Clicking on the 'bell' shows '1 scheduled change' under Alerts. The scheduled change is 'EC2 persistent instance retirement scheduled' with a status of 'upcoming'. And the instance is i-dcd740d1. So, I'm hoping someone can shed some light on which to believe. Will the instance disappear April 3, 2017, at 12:00:00 PM UTC-4 as indicated in the scheduled change or is this a leftover message? Thanks in advance for any insight you can provide! jerry", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252391&tstart=0"},
{"Answers": {"usr-1": ["Good Morning Instance ID i-ec6d4710 on account 612796086932 is stuck on \"stopping\" status. The host machine is scheduled for retirement. Could you please assist in stopping this instance so that it can be moved to a new host."], "usr-2": ["The instance has been restarted and moved to a new host. I'm able to ssh into the box. I no longer need assistance."], "usr-3": ["Situation fixed itself."]}, "Question": "Good Morning Instance ID i-ec6d4710 on account 612796086932 is stuck on 'stopping' status. The host machine is scheduled for retirement. Could you please assist in stopping this instance so that it can be moved to a new host.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252404&tstart=0"},
{"Answers": {"usr-1": ["So, I'm trying to get a very bare-bones app instance (based on amzn-ami-hvm-2016.09.1.20170119-x86_64-gp2 (ami-0b33d91d)) up and running. Installation of all the packages works without issues, restart the httpd service and confirmed that the system is listening on TCP/80 and TCP/443. Connections (via browser) to :80 work as expected. Connections to :443 do not. The browser hangs and after some time insists that it can't make a secure connection to the server. Additionally, if I try to connect to the web server using the openssl application as follows: openssl s_client -connect 172.19.32.31:443 I get the following output: CONNECTED(00000003) < long pause > 13613:error:140790E5:SSL routines:SSL23_WRITE:ssl handshake failure:/BuildRoot/Library/Caches/com.apple.xbs/Sources/OpenSSL098/OpenSSL098-64.50.6/src/ssl/s23_lib.c:185: The documentation makes this seem very straightforward and idiot-proof, but my experience does not bear that out. What am I doing wrong? TIA! A couple of updates. I wanted to add to my setup that I have confirmed that the security groups associated with the instance permit access to TCP/80 and TCP/443 from anywhere. Additionally, when I try openssl s_client -connect localhost:443 from the local system, I get: CONNECTED(00000003) depth=0 C = --, ST = SomeState, L = SomeCity, O = SomeOrganization, OU = SomeOrganizationalUnit, CN = ip-172-19-32-31, emailAddress = root@ip-172-19-32-31 verify error:num=18:self signed certificate verify return:1 depth=0 C = --, ST = SomeState, L = SomeCity, O = SomeOrganization, OU = SomeOrganizationalUnit, CN = ip-172-19-32-31, emailAddress = root@ip-172-19-32-31 verify return:1 --- Certificate chain 0 s:/C=--/ST=SomeState/L=SomeCity/O=SomeOrganization/OU=SomeOrganizationalUnit/CN=ip-172-19-32-31/emailAddress=root@ip-172-19-32-31 i:/C=--/ST=SomeState/L=SomeCity/O=SomeOrganization/OU=SomeOrganizationalUnit/CN=ip-172-19-32-31/emailAddress=root@ip-172-19-32-31 --- Server certificate -----BEGIN CERTIFICATE----- MIIENzCCAx+gAwIBAgICJekwDQYJKoZIhvcNAQELBQAwga8xCzAJBgNVBAYTAi0t MRIwEAYDVQQIDAlTb21lU3RhdGUxETAPBgNVBAcMCFNvbWVDaXR5MRkwFwYDVQQK DBBTb21lT3JnYW5pemF0aW9uMR8wHQYDVQQLDBZTb21lT3JnYW5pemF0aW9uYWxV bml0MRgwFgYDVQQDDA9pcC0xNzItMTktMzItMzExIzAhBgkqhkiG9w0BCQEWFHJv b3RAaXAtMTcyLTE5LTMyLTMxMB4XDTE3MDMyODE3MzAwNloXDTE4MDMyODE3MzAw Nlowga8xCzAJBgNVBAYTAi0tMRIwEAYDVQQIDAlTb21lU3RhdGUxETAPBgNVBAcM CFNvbWVDaXR5MRkwFwYDVQQKDBBTb21lT3JnYW5pemF0aW9uMR8wHQYDVQQLDBZT b21lT3JnYW5pemF0aW9uYWxVbml0MRgwFgYDVQQDDA9pcC0xNzItMTktMzItMzEx IzAhBgkqhkiG9w0BCQEWFHJvb3RAaXAtMTcyLTE5LTMyLTMxMIIBIjANBgkqhkiG 9w0BAQEFAAOCAQ8AMIIBCgKCAQEAx2KEUldTRiN45dYjgiSFaLTKInuqNAckTB56 WTF2QVoMI2JLj5L0r5G+Uw3964AgAim8cHMDbFMajMPeWsnnRwRtIOV/eEGC4wx8 JMTogxGooA1huX/q+1b20xesQByQ0CwR8kyxigjVWSrX1BriR43Q9/7qJYM/gf9l rVRhBkU/p4s203IgYqvjyGDBdCkFSZ969EqW5dIfiA8KXLdZKiRg4lU36GB+wsDS 867pfIR3+ZiUoj2GQ4yXjgxJaBCG/ze7oCEkAfiiOHAXeDrRyT+FskXJgWOcVjxh MvaqZY8KJzGxJyzf05Ir/qdblsOUkgn/Vq66tZEuLoNzqFbcdQIDAQABo1swWTAM BgNVHRMEBTADAQH/MDwGA1UdEQQ1MDOCCWxvY2FsaG9zdIIVbG9jYWxob3N0Lmxv Y2FsZG9tYWlugg9pcC0xNzItMTktMzItMzEwCwYDVR0PBAQDAgLkMA0GCSqGSIb3 DQEBCwUAA4IBAQCwkEAqgkFl9J7WYVLfdpIVKlWYeIaPZ0c8cBBwlr1bgjbzo60l orxyvez/DftEugi8f2P+v3QbHQPbWxlOTOpdpWeEvUoUb0LwSex4XtTErZcc6uHh 1SAVcf2CW617IZFeOn6uVXqRSY3Vf1th7u7w3Rq7YA9KWOOAcYvzwafy0IvL9wmA OIVjo8GJ+jaGlIy4wC9CRO7gPiF8j6Tz6S0bw9CQSN91FnWeBXDyMnyyVhSUxHsx KPmWD42eN8AQykZ8kbUitAmpfJgQyF4j3zBd1ea3ft9zxajVZETapdtsZ5ny2BdG oKGqTKQuFmIMG5TuiUINPeFSp+lt0YMB3uto -----END CERTIFICATE----- subject=/C=--/ST=SomeState/L=SomeCity/O=SomeOrganization/OU=SomeOrganizationalUnit/CN=ip-172-19-32-31/emailAddress=root@ip-172-19-32-31 issuer=/C=--/ST=SomeState/L=SomeCity/O=SomeOrganization/OU=SomeOrganizationalUnit/CN=ip-172-19-32-31/emailAddress=root@ip-172-19-32-31 --- No client certificate CA names sent Server Temp Key: ECDH, prime256v1, 256 bits --- SSL handshake has read 1774 bytes and written 375 bytes --- New, TLSv1/SSLv3, Cipher is ECDHE-RSA-AES256-GCM-SHA384 Server public key is 2048 bit Secure Renegotiation IS supported Compression: NONE Expansion: NONE SSL-Session: Protocol : TLSv1.2 Cipher : ECDHE-RSA-AES256-GCM-SHA384 Session-ID: 6CDA64E503F4EBCC839008E76E331DD24ADD9139063264ACDD6A54B7883E5643 Session-ID-ctx: Master-Key: 90418F43E8EE18BF5886BFD9A780449FFABF60730591C9E33A6ABA0511B128F1C5719688E32CC30BC1BCFE07AA805EE9 Key-Arg : None Krb5 Principal: None PSK identity: None PSK identity hint: None TLS session ticket lifetime hint: 300 (seconds) TLS session ticket: 0000 - 58 c2 16 a2 ad 17 c8 cf-f2 b7 bc e8 a1 5a 4d 4f X............ZMO 0010 - 74 bf fe 6e 12 ed c8 fb-82 cc 00 93 10 1a 28 a9 t..n..........(. 0020 - d8 9c 39 4e e0 10 df 56-d2 65 ce f3 71 97 c1 0a ..9N...V.e..q... 0030 - 21 03 da 5a 9e d8 ef e0-4c d7 d7 f9 f1 a8 90 76 !..Z....L......v 0040 - ef 53 ff 5e 3c 61 65 2f-b5 43 9e 34 1e fd ff 8d .S.^<ae/.C.4.... 0050 - a8 47 05 1e 8d f5 df 87-b1 53 f3 ca 58 23 97 2a .G.......S..X#.* 0060 - e4 0e 13 03 95 af 12 1a-cc ab 8d 5f 3f 4e fc c2 ..........._?N.. 0070 - 02 27 e9 c0 c1 3b 57 8a-35 bc 1c b2 e7 64 83 ac .'...;W.5....d.. 0080 - af ba ea e1 05 36 50 4c-43 8e d0 1a 65 ca 53 7c .....6PLC...e.S| 0090 - b4 2f 99 1a 6b e6 75 03-20 e7 2a 07 e1 16 e3 ee ./..k.u. .*..... 00a0 - c1 38 b6 84 3c 03 64 76-4b d8 28 62 f1 9b 16 ec .8..<.dvK.(b.... 00b0 - 34 52 2c 8e b8 56 d2 24-ea 25 ab 8b 07 54 cb 9e 4R,..V.$.%...T.. \u00a0 Start Time: 1490725517 Timeout : 300 (sec) Verify return code: 18 (self signed certificate) --- closed So THAT seems to be working...why would it not work remotely?? Edited by: jramz-galsheram on Mar 28, 2017 11:29 AM"], "usr-2": [":-} I'm an idiot... I was changing the wrong security group to permit SSL. Derp. Thanks and sorry."]}, "Question": "So, I'm trying to get a very bare-bones app instance (based on amzn-ami-hvm-2016.09.1.20170119-x86_64-gp2 (ami-0b33d91d)) up and running. Installation of all the packages works without issues, restart the httpd service and confirmed that the system is listening on TCP/80 and TCP/443. Connections (via browser) to :80 work as expected. Connections to :443 do not. The browser hangs and after some time insists that it can't make a secure connection to the server. Additionally, if I try to connect to the web server using the openssl application as follows: openssl s_client -connect 172.19.32.31:443 I get the following output: CONNECTED(00000003) < long pause > 13613:error:140790E5:SSL routines:SSL23_WRITE:ssl handshake failure:/BuildRoot/Library/Caches/com.apple.xbs/Sources/OpenSSL098/OpenSSL098-64.50.6/src/ssl/s23_lib.c:185: The documentation makes this seem very straightforward and idiot-proof, but my experience does not bear that out. What am I doing wrong? TIA! A couple of updates. I wanted to add to my setup that I have confirmed that the security groups associated with the instance permit access to TCP/80 and TCP/443 from anywhere. Additionally, when I try openssl s_client -connect localhost:443 from the local system, I get: CONNECTED(00000003) depth=0 C = --, ST = SomeState, L = SomeCity, O = SomeOrganization, OU = SomeOrganizationalUnit, CN = ip-172-19-32-31, emailAddress = root@ip-172-19-32-31 verify error:num=18:self signed certificate verify return :1 depth=0 C = --, ST = SomeState, L = SomeCity, O = SomeOrganization, OU = SomeOrganizationalUnit, CN = ip-172-19-32-31, emailAddress = root@ip-172-19-32-31 verify return :1 --- Certificate chain 0 s:/C=--/ST=SomeState/L=SomeCity/O=SomeOrganization/OU=SomeOrganizationalUnit/CN=ip-172-19-32-31/emailAddress=root@ip-172-19-32-31 i:/C=--/ST=SomeState/L=SomeCity/O=SomeOrganization/OU=SomeOrganizationalUnit/CN=ip-172-19-32-31/emailAddress=root@ip-172-19-32-31 --- Server certificate -----BEGIN CERTIFICATE----- MIIENzCCAx+gAwIBAgICJekwDQYJKoZIhvcNAQELBQAwga8xCzAJBgNVBAYTAi0t MRIwEAYDVQQIDAlTb21lU3RhdGUxETAPBgNVBAcMCFNvbWVDaXR5MRkwFwYDVQQK DBBTb21lT3JnYW5pemF0aW9uMR8wHQYDVQQLDBZTb21lT3JnYW5pemF0aW9uYWxV bml0MRgwFgYDVQQDDA9pcC0xNzItMTktMzItMzExIzAhBgkqhkiG9w0BCQEWFHJv b3RAaXAtMTcyLTE5LTMyLTMxMB4XDTE3MDMyODE3MzAwNloXDTE4MDMyODE3MzAw Nlowga8xCzAJBgNVBAYTAi0tMRIwEAYDVQQIDAlTb21lU3RhdGUxETAPBgNVBAcM CFNvbWVDaXR5MRkwFwYDVQQKDBBTb21lT3JnYW5pemF0aW9uMR8wHQYDVQQLDBZT b21lT3JnYW5pemF0aW9uYWxVbml0MRgwFgYDVQQDDA9pcC0xNzItMTktMzItMzEx IzAhBgkqhkiG9w0BCQEWFHJvb3RAaXAtMTcyLTE5LTMyLTMxMIIBIjANBgkqhkiG 9w0BAQEFAAOCAQ8AMIIBCgKCAQEAx2KEUldTRiN45dYjgiSFaLTKInuqNAckTB56 WTF2QVoMI2JLj5L0r5G+Uw3964AgAim8cHMDbFMajMPeWsnnRwRtIOV/eEGC4wx8 JMTogxGooA1huX/q+1b20xesQByQ0CwR8kyxigjVWSrX1BriR43Q9/7qJYM/gf9l rVRhBkU/p4s203IgYqvjyGDBdCkFSZ969EqW5dIfiA8KXLdZKiRg4lU36GB+wsDS 867pfIR3+ZiUoj2GQ4yXjgxJaBCG/ze7oCEkAfiiOHAXeDrRyT+FskXJgWOcVjxh MvaqZY8KJzGxJyzf05Ir/qdblsOUkgn/Vq66tZEuLoNzqFbcdQIDAQABo1swWTAM BgNVHRMEBTADAQH/MDwGA1UdEQQ1MDOCCWxvY2FsaG9zdIIVbG9jYWxob3N0Lmxv Y2FsZG9tYWlugg9pcC0xNzItMTktMzItMzEwCwYDVR0PBAQDAgLkMA0GCSqGSIb3 DQEBCwUAA4IBAQCwkEAqgkFl9J7WYVLfdpIVKlWYeIaPZ0c8cBBwlr1bgjbzo60l orxyvez/DftEugi8f2P+v3QbHQPbWxlOTOpdpWeEvUoUb0LwSex4XtTErZcc6uHh 1SAVcf2CW617IZFeOn6uVXqRSY3Vf1th7u7w3Rq7YA9KWOOAcYvzwafy0IvL9wmA OIVjo8GJ+jaGlIy4wC9CRO7gPiF8j6Tz6S0bw9CQSN91FnWeBXDyMnyyVhSUxHsx KPmWD42eN8AQykZ8kbUitAmpfJgQyF4j3zBd1ea3ft9zxajVZETapdtsZ5ny2BdG oKGqTKQuFmIMG5TuiUINPeFSp+lt0YMB3uto -----END CERTIFICATE----- subject=/C=--/ST=SomeState/L=SomeCity/O=SomeOrganization/OU=SomeOrganizationalUnit/CN=ip-172-19-32-31/emailAddress=root@ip-172-19-32-31 issuer=/C=--/ST=SomeState/L=SomeCity/O=SomeOrganization/OU=SomeOrganizationalUnit/CN=ip-172-19-32-31/emailAddress=root@ip-172-19-32-31 --- No client certificate CA names sent Server Temp Key: ECDH, prime256v1, 256 bits --- SSL handshake has read 1774 bytes and written 375 bytes --- New, TLSv1/SSLv3, Cipher is ECDHE-RSA-AES256-GCM-SHA384 Server public key is 2048 bit Secure Renegotiation IS supported Compression: NONE Expansion: NONE SSL-Session: Protocol : TLSv1.2 Cipher : ECDHE-RSA-AES256-GCM-SHA384 Session-ID: 6CDA64E503F4EBCC839008E76E331DD24ADD9139063264ACDD6A54B7883E5643 Session-ID-ctx: Master-Key: 90418F43E8EE18BF5886BFD9A780449FFABF60730591C9E33A6ABA0511B128F1C5719688E32CC30BC1BCFE07AA805EE9 Key-Arg : None Krb5 Principal: None PSK identity: None PSK identity hint: None TLS session ticket lifetime hint: 300 (seconds) TLS session ticket: 0000 - 58 c2 16 a2 ad 17 c8 cf-f2 b7 bc e8 a1 5a 4d 4f X............ZMO 0010 - 74 bf fe 6e 12 ed c8 fb-82 cc 00 93 10 1a 28 a9 t..n..........(. 0020 - d8 9c 39 4e e0 10 df 56-d2 65 ce f3 71 97 c1 0a ..9N...V.e..q... 0030 - 21 03 da 5a 9e d8 ef e0-4c d7 d7 f9 f1 a8 90 76 !..Z....L......v 0040 - ef 53 ff 5e 3c 61 65 2f-b5 43 9e 34 1e fd ff 8d .S.^<ae/.C.4.... 0050 - a8 47 05 1e 8d f5 df 87-b1 53 f3 ca 58 23 97 2a .G.......S..X#.- 0060 - e4 0e 13 03 95 af 12 1a-cc ab 8d 5f 3f 4e fc c2 ..........._?N.. 0070 - 02 27 e9 c0 c1 3b 57 8a-35 bc 1c b2 e7 64 83 ac . '...;W.5....d.. 0080 - af ba ea e1 05 36 50 4c-43 8e d0 1a 65 ca 53 7c .....6PLC...e.S| 0090 - b4 2f 99 1a 6b e6 75 03-20 e7 2a 07 e1 16 e3 ee ./..k.u. .-..... 00a0 - c1 38 b6 84 3c 03 64 76-4b d8 28 62 f1 9b 16 ec .8..<.dvK.(b.... 00b0 - 34 52 2c 8e b8 56 d2 24-ea 25 ab 8b 07 54 cb 9e 4R,..V.$.\\%...T.. \u00a0 Start Time: 1490725517 Timeout : 300 (sec) Verify return code: 18 (self signed certificate) --- closed So THAT seems to be working...why would it not work remotely?? Edited by: jramz-galsheram on Mar 28, 2017 11:29 AM", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252453&tstart=0"},
{"Answers": {"usr-1": ["Hi there, On my instance ID:i-3973acf7 i cant even ping google.com I can't apt-get update, no HTTP is out going, infact nothing is allowed out. UFW is disabled, and i've tried different security groups and security settings to no avail. I can SSH in and HTTP in is sweet, but nothing seems to be allowed out. I'm completely stuck now, any help much appreciated."], "usr-2": ["Hi, I looked at the instance, the security group and network acls are allowing all outgoing traffic. I do not see the security group or network acl rules blocking the egress traffic unless you have some iptable rules configured. Thanks!!!"], "usr-3": ["Ran some more tests, not able to access the internal DNS either: ubuntu@testnet:~$ cat /etc/resolv.conf # Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8) # DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN nameserver 172.31.0.2 search ap-southeast-2.compute.internal ubuntu@testnet:~$ dig google.com \u00a0 ; <<>> DiG 9.10.3-P4-Ubuntu <<>> google.com ;; global options: +cmd ;; connection timed out; no servers could be reached"], "usr-4": ["Yep you're right it was the iptables. Thanks for the help"]}, "Question": "Hi there, On my instance ID:i-3973acf7 i cant even ping google.com I can't apt-get update, no HTTP is out going, infact nothing is allowed out. UFW is disabled, and i've tried different security groups and security settings to no avail. I can SSH in and HTTP in is sweet, but nothing seems to be allowed out. I'm completely stuck now, any help much appreciated.", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252401&tstart=0"},
{"Answers": {"usr-1": ["I have an r3.Large EC2 instance running in eu-west-1a. This is also connected to an annual Reserved Instance with a 'scope' = 'Availability Zone' and 'Zone' = eu-west-1a. As the RI was about to expire tomorrow, I purchased a new one year RI now. I chose to 'Purchase More Like These' from the actions button. After having processed my purchase I now have a new reserved instance with a 'scope' of 'Region' with the 'Availability Zone' blank. I was offered no other options during the purchase process. Can anyone assure me that this will match up with my live instance when my current RI expires tomorrow ? Edited by: DavyBoy on Mar 25, 2017 12:40 AM"], "usr-2": ["Hi, I understand you have realized that the RI on your account was about to expire and used the \u201cPurchase More Like These\u201dbutton from the management console to purchase a RI but upon completion of the purchase you have realized that the new RI is slightly different from the old RI as the value for AZ is blank and you would like to make sure the discount benefit still applies to your live or on-demand instance after your current RI expires. Is that right? \u2014>Can anyone assure me that this will match up with my live instance when my current RI expires tomorrow ? Yes, with your current setup the discount should continue to apply but there are some caveats. With recent changes to Reserved Instance, (RI) it comes in two different flavors namely Standard RI and Convertible RI. The AWS blog post [1] has more concise information related to RI and available features. Standard Reserved Instances [2] can be purchased to apply to instances in a specific Availability Zone, or to instances in a region. [2] I checked your account and I can see the RI you have purchase is Standard RI with regional benefit and the AZ is empty. When you purchase RI with Regional benefit, the discount will be applied to any instances within the region and the RI discount is not constrained to a particular AZ. (eu-west-1a) While the discount is applied to all instance within the region, you however lose the ability to make capacity reservation. On the other hand, when you purchase RI with AZ benefit, the discount is only applied to instance running on the AZ specified but RI with specific AZ provides Capacity reservation. Capacity Reservation guarantees that you will have an option to start an instance within the AZ you have purchase RI. (AZ specific) [3] This is beneficial if you have a need to reserve capacity on a particular AZ. (eu-west-1a) The good news is, it is entirely possible to modify Standard Reserved [4] Instances purchased for a specific Availability Zone to a region\u2014but doing so removes the associated capacity reservation. I hope the information helps minimize your concerns. References: 1.https://aws.amazon.com/blogs/aws/ec2-reserved-instance-update-convertible-ris-and-regional-benefit/ 2.http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/reserved-instances-types.html 3.https://aws.amazon.com/ec2/pricing/reserved-instances/ 4.http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-modifying.html"], "usr-3": ["Thank you for your reply. Unfortunately I'm still confused. I'm not clear what 'capacity reservation' means. For example, if I stop and start my instance for a reboot for example will the reserved instance apply the discount to my restarted instance ? Do I need to do anything at all right now ? Alternatively if I modify my reserved instance to 'Availability Zone' 'eu-west-1A' 'EC2-Classic' will it be exactly the same as the current reserved instance I purchased one year ago, that's about to expire today ? My current EC2 live instance is a production system that I don't foresee changing in the next 12 months i.e. it will not be moving between availability zones etc... I need to ensure that the reserved instance I purchased yesterday will apply the discount to that live instance for the next 12 months. Edited by: DavyBoy on Mar 26, 2017 5:04 AM"], "usr-4": ["Bump : Any chance you could help again with this ? \" While the discount is applied to all instance within the region, you however lose the ability to make capacity reservation. \" I'm unclear what 'capacity reservation' means Can you please let me know what this means and how it will affect my situation ? I have a production system running a single instance in eu-west-1a... and I foresee it remaining in that state for some time. From what you said, it seems the reserved instance discount is currently applied to my situation but under what conditions does the reserved instance discount cease to be applied ? After a reboot ? Thanks in advance for all your help."], "usr-5": ["Hello, EC2 has certain capacities in each AZ for each instance type. In general our scaling teams try to scale out each instance type to be available for customer use across all AZs, however with older instance types and depending on the situation you might not be able to launch a particular instance type in a specific AZ. With reserved instances, capacity reservation would ensure that you have the ability to launch that instance type in that specific AZ as it's reserved for that account, even if normal availability for that instance type in that AZ was not available for others who hadn't reserved. Regards, Nick"], "usr-6": ["All clear now. Thanks Nick."]}, "Question": "I have an r3.Large EC2 instance running in eu-west-1a. This is also connected to an annual Reserved Instance with a 'scope' = 'Availability Zone' and 'Zone' = eu-west-1a. As the RI was about to expire tomorrow, I purchased a new one year RI now. I chose to 'Purchase More Like These' from the actions button. After having processed my purchase I now have a new reserved instance with a 'scope' of 'Region' with the 'Availability Zone' blank. I was offered no other options during the purchase process. Can anyone assure me that this will match up with my live instance when my current RI expires tomorrow ? Edited by: DavyBoy on Mar 25, 2017 12:40 AM", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252232&tstart=0"},
{"Answers": {"usr-1": ["These new I/O optimized instances were announced about a month ago and look great. https://aws.amazon.com/blogs/aws/now-available-i3-instances-for-demanding-io-intensive-applications/ However, some colleagues are claiming these instances will lose all data on them if you happen to turn off these i3 instances. Does this sound accurate? If so, what best practices would be recommended in order to take advantage of these new instance types?"], "usr-2": ["This does not appear to be limited to i3. Twice now i have had a t2 reboot after updates and lose every single piece of data on it."], "usr-3": ["Hi, The data stored on Ephemeral/Instance store volumes will be lost on Instance Stop and Start. Please refer our documentation here: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html Hope this helps. Regards, Jayakrishnan L"], "usr-4": ["Thank that does answer my question. I do have a follow-up to this if someone is willing to comment. Why is Amazon promoting this as a database storage solution if data can be lost so easily? Are most only using these drives for temporary storage like TempDB or are most using for a persistent database but just have a good replication and backup strategy in place?"], "usr-5": ["The ephemeral storage is good for high speed processing; you will need to map EBS volumes and copy processed data there (within your App, etc.) for persistent storage."]}, "Question": "These new I/O optimized instances were announced about a month ago and look great. https://aws.amazon.com/blogs/aws/now-available-i3-instances-for-demanding-io-intensive-applications/ However, some colleagues are claiming these instances will lose all data on them if you happen to turn off these i3 instances. Does this sound accurate? If so, what best practices would be recommended in order to take advantage of these new instance types?", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252621&tstart=0"},
{"Answers": {"usr-1": ["When trying to take a snapshot of a drive that is no longer being written to (or read from for that matter), the resulting snapshot is almost entirely empty. I am not turning off the instance or unmounting the drive because I need this process to permit snapshot creation while read actions are taking place. The drive is 3000GB in size. I sorted it out. Turns out that I am using cloudformation and had forgotten that I was formatting the drive. My bad!"]}, "Question": "When trying to take a snapshot of a drive that is no longer being written to (or read from for that matter), the resulting snapshot is almost entirely empty. I am not turning off the instance or unmounting the drive because I need this process to permit snapshot creation while read actions are taking place. The drive is 3000GB in size. I sorted it out. Turns out that I am using cloudformation and had forgotten that I was formatting the drive. My bad!", "Title": "", "awsTag": "EC2", "crawled": true, "dateScraped": "2017-04-05-17-34", "sourceUri": "https://forums.aws.amazon.com/thread.jspa?threadID=252603&tstart=0"}]